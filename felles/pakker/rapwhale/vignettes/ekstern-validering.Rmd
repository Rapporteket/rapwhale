---
title: "Ekstern validering"
author: "Per Erik Haugedal og Karl Ove Hufthammer"
output:
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Ekstern validering}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r pakkelasting, include = FALSE}
suppressPackageStartupMessages({
  library(rapwhale)
  library(dplyr)
  library(kableExtra)
})
```

```{r kable-format, include = FALSE}
lag_kable = function(d, full_width = FALSE, ...) {
  d %>%
    kbl() %>%
    kable_styling("hover", full_width = full_width, ...)
}
```

```{css, echo=FALSE}
/* Hack for å få tabellar til å flyt ut i margen om nødvendig
   (fixme: bør erstattast med eit felles, eksternt og
           gjennomtenkt stilsett for alle vignettane) */
table { float: left; }
p, h1, h2, h3, h4, h5, h6, div {
  clear: both;
}
```


## Innleiing

I `rapwhale` finst ein infrastruktur – eit sett R-funksjonar og tilhøyrande
metodikk – for *ekstern validering* av registerdata. Målet med denne
har vore å gjera det enklare, raskare og sikrare å gjennomføra ekstern
validering av høg kvalitet.

*Ekstern validering* går her ut på å finna ut om dataa i registeret er 
lik dataa i ein gitt gullstandard, typisk ein pasientjournal.
For meir informasjon, sjå
[SKDE sin artikkel om korrektheit](https://www.kvalitetsregistre.no/korrekthet).

Me har laga eit standardisert format for valideringsdata og
eit sett R-funksjonar for å analysera og laga datasett på dette formatet.
La oss først sjå nærare på formatet me har komme fram til.


## Format til valideringsdatasett

I eit valideringsdatsett må me for kvar måling
(for eksempel vekta eller høgda til ein person)
registrera verdien av målinga i registeret (*intern verdi*) og
tilhøyrande verdi i den eksterne kjelda (*ekstern verdi*), gullstandarden.
I tillegg treng me informasjon om kva pasient eller forløp
verdien gjeld samt kva for variabel det er snakk om.

### Første forsøk på eit format

I utgangspunktet verkar eit format som dette fornuftig:

```{r superenkelt eksempel, echo = FALSE}
d_banalt = tibble::tribble(
  ~pasid, ~varnamn, ~verdi_intern, ~verdi_ekstern,
  5, "vekt", 78, 78,
  7, "vekt", 53, 53,
  7, "hogd", 196, 186
)
lag_kable(d_banalt)
```

Her kan me registrera høgda og vekta til kvar pasient
(identifisert med pasient-ID, `pasid`),
både internt i registeret og i den eksterne kjelda.

Men for meir realistiske datasett støyter me fort på problem,
som me har løyst med eit utvida og endeleg format.


### Utvida og endeleg format

Det er tre potensielle problem –
at ein pasient kan ha *fleire målingar* av same variabel,
at me kan ha målingar av *ulike datatypar* (eksempelvis både tal og datoar)
og at indeksvariablar kan ha *same namn* som verdivariablane.

Ein pasient kan ha *fleire målingar* av same variabel
dersom han vore til fleire undersøkingar.
Det løyser me enkelt ved å tillata fleire *indeksvariablar*,
for eksempel både pasient-ID og undersøkingsdato.
Dette er variablar som saman med `vld_varnamn` unikt identifiserer kvar måling.
(Det svarar altså til *primærnøklar* i databasar.)

Eit register har vanlegvis målingar av *ulike datatypar*,
for eksempel både tal (som ovanfor) og datoar eller logiske variablar
(`TRUE`/`FALSE`).
Men i dei fleste datasystem kan ein kolonne berre innehalda data av éin type.
Dette løyser me ved å innføra fleire verdikolonnar,
éin for kvar datatype.
Me treng då òg ein kolonne (`vld_vartype`) som seier kva type variabel
som kvar verdi gjeld.

I sjeldne tilfelle har indeksvariablar *same namn* som verdivariablane.
Det prøver me å løysa ved at alle variablar utanom indeksvariablane
får prefikset *vld_* («validering»).
Dette vert då å rekna som eit reservert prefiks.

I det endelege formatet er det framleis slik at kvar rad
indentifiserer ei *måling* (med to verdiar, éin intern og éin ekstern):

```{r eksempel format, echo = FALSE}
d_format = tibble::tribble(
  ~pasid, ~dato_inn, ~vld_varnamn, ~vld_vartype, ~vld_verdi_intern_dato, ~vld_verdi_ekstern_dato, ~vld_verdi_intern_tal, ~vld_verdi_ekstern_tal,
  5, as.Date("2020-06-07"), "vekt", "tal", NA, NA, 78, 78,
  5, as.Date("2020-06-07"), "dato_ut", "dato", as.Date("2020-06-15"), as.Date("2020-06-15"), NA, NA,
  5, as.Date("2020-12-13"), "vekt", "tal", NA, NA, 50, 50,
  5, as.Date("2020-12-13"), "dato_ut", "dato", as.Date("2020-12-13"), as.Date("2020-12-14"), NA, NA,
  7, as.Date("2020-08-07"), "vekt", "tal", NA, NA, 53, 53,
  7, as.Date("2020-08-09"), "hogd", "tal", NA, NA, 196, 194,
  7, as.Date("2020-08-09"), "dato_ut", "dato", as.Date("2020-08-13"), as.Date("2020-08-13"), NA, NA
)
lag_kable(d_format)
```

Her utgjer `pasid` (pasient-ID) og `dato_inn` (innskrivingsdato)
indeksvariablane som *saman* unikt identifiserer ei måling (rad).
Pasient 5 har hatt to opphald og pasient 7 eitt.
Me vil samanlikna kva verdiar dei tre variablane
`vekt` (vekta til pasienten),
`hogd` (høgda til pasienten)
og `dato_ut` (utskrivingsdatoen for pasienten)
har i registeret med tilhøyrande verdiar i den eksterne kjelda.


## Bruk av valideringsdatasett

Når me har eit ferdig utfylt valideringsdatsett,
er det svært lett å samananlikna dei interne og eksterne verdiane.
Så kan me rekna ut statistikk som seier kor korrekte dataa er,
og til slutt kan me bruka statistikken i tabellar og
figurar i valideringsrapportar.


### Samanlikning av interne og eksterne verdiar

Til å samanlikna verdiane brukar me `analyser_valideringsdatasett()`:

```{r samanlikning}
d_vld = d_format
d_samanlikna = d_vld %>%
  analyser_valideringsdatasett()
```

```{r, echo = FALSE}
lag_kable(d_samanlikna)
```

Den nye kolonnen `ki_krit_teller` seier om dei interne og
dei eksterne verdiane er *like*.
Merk at to `NA`-verdiar som standard vert rekna som like
(noko som ikkje er vanleg i R).
Tanken bak dette er at om for eksempel `vekt` ikkje er registrert i registeret,
så *skal* heller ikkje vektinformasjon finnast i pasientjournalen,
og vice versa.

Men dersom gullstandarden og registeret ikkje har same *kjelde* til data,
for eksempel viss me samanliknar pasient- og legerapporterte data,
kan me ynskja eit visst slingringsmonn ved samanlikningane.
Me kan for eksempel ynskja at måling av vekt skal ha eit slingringsmonn
på 4 (kg), måling av høgd skal ha eit slingringsmonn på 2 (cm),
men operasjonsdatoen må vera heilt nøyaktig.
Dette kan ein få til ved å laga eigne *samanliknarfunksjonar*
(argumentet `samanliknar`).
Sjå meir om samanliknarfunksjonar i avsnitt **fixme**.



### Utrekning av korrektheitsstatistikk

Som vist ovanfor, legg `analyser_valideringsdatasett()` til *to* kolonnar,
`ki_krit_teller`, som me alt har sett på,
og `ki_krit_nevner`, som er `TRUE` for alle radene.
I praksis lagar me ein altså eit formelt kvalitetsindikator-datasett
(sjå **fixme: lenkje til vignett om kvalitetsindikatorar**),
noko som gjer at me kan bruka `aggreger_ki_prop()`
for å rekna ut korrektheitstatistikk,
både totalt og stratifisert på éin eller fleire variablar.


#### Total korrektheit

Total korrektheit reknar me ut direkte:

```{r aggregering total}
d_samanlikna %>%
  aggreger_ki_prop()
```

```{r, include=FALSE}
# Hack for å kunna ha tilgang til resultata i teksten
# utan å laga eksplisitt variabelnamn i eksempelet
d_agg_total = aggreger_ki_prop(d_samanlikna)
```

Her ser me at `r d_agg_total$ki_teller` av `r d_agg_total$ki_nevner`
(`r round(100*d_agg_total$est)` %)
av verdiane var like i registeret og gullstandarden.
Me får òg ut tilhøyrande 95 %-konfidensintervall.


#### Korrektheit per variabel/sjukehus

Nokre variablar er gjerne oftare korrekt registrerte enn andre:

```{r aggregering per-variabel}
d_samanlikna %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()
```

Tilsvarande kan me rekna ut korrektheit per sjukehus,
per variabel per sjukehus,
eller over tid (ved å ha år og månad som grupperingsvariablar).


#### Bruk av statistikken

Til slutt kan me visa statistikken i fine tabellar og figurar.
Her er eit komplett eksempel på bruk av eit valideringsdatasett,
med figur:

```{r, fig.width=5}
# Rekn ut korrektheit per variabel
d_korrektheit = d_vld %>%
  analyser_valideringsdatasett() %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()

# Eventuelt sorter for å få finare grafar og tabellar
d_korrektheit_sortert = d_korrektheit %>%
  arrange(est) %>%
  mutate(varnamn_sortert = forcats::fct_inorder(vld_varnamn))
# Brukte her arrange() for at resultatet lett skal kunna brukast
# i tabellar òg. Skal me berre laga grafar, kunne me heller bruka
# forcats::fct_reorder() direkte i mutate()-steget.
# I mutate()-steget kan me godt òg laga finare variabelnamn ...

# Enkel figur
library(ggplot2)
ggplot(
  d_korrektheit_sortert,
  aes(
    x = est, xmin = konfint_nedre, xmax = konfint_ovre,
    y = varnamn_sortert
  )
) +
  geom_pointrange() +
  scale_x_continuous(labels = scales::percent) +
  ggtitle("Korrektheit for utvalde variablar") +
  xlab("Korrekt") +
  ylab(NULL)
```

Her kan (og bør) me sjølvsagt finpussa figuren for å gjera
han meir brukarvennleg, men det er ikkje tema for denne vignetten.

Me tilrår elles òg *sterkt* å bruka SPC-metodikk,
*ikkje* konfidensintervall,
for samanlikning av korrektheit,
for eksempel mellom ulike sjukehus eller over tid,
men det er heller ikkje tema her.



## Generering av valideringsdatasett

Når ein har registerdata, er det med denne pakken veldig lett å
laga eit valideringsdatasett. Ein gjev inn eit datasett med indeksvariablar
og datavariablar, og ein vektor med namna på indeksvariablane til funksjonen 
`lag_valideringsdatasett()` og får ut eit valideringsdatasett.

### Eksempel på register

Me har eit enkelt register som registrerer vekt, høgd, om pasienten har opplevd
biverknad, kva type biverknad og om pasienten er gravid. Nokre av variablane i 
registeret kan sjå slik ut:

```{r lageksempel, echo = FALSE}
d_reg_full = tibble::tribble(
  ~pasid, ~dato_inn, ~kjonn, ~sjukehus, ~dato_ut, ~vekt, ~hogd, ~biverk, ~biverk_hovud, ~biverk_mage, ~biverk_fot, ~gravid,
  5, as.Date("2020-06-07"), "M", "Bergen", as.Date("2020-06-15"), 78, 183, TRUE, FALSE, TRUE, TRUE, NA,
  5, as.Date("2020-12-13"), "M", "Førde", as.Date("2020-12-13"), 50, 179, TRUE, FALSE, TRUE, TRUE, NA,
  7, as.Date("2020-08-09"), "K", "Bergen", as.Date("2020-08-13"), 711, 196, TRUE, TRUE, TRUE, TRUE, TRUE,
  13, as.Date("2021-01-05"), "M", "Førde", NA, NA, 163, FALSE, NA, NA, NA, NA,
  14, as.Date("2021-01-05"), "M", "Førde", as.Date("2021-01-09"), 101, 182, TRUE, TRUE, FALSE, FALSE, NA
)
lag_kable(d_reg_full)
```

I dette eksempelet er indeksvariablane `pasid` og `dato_inn`, medan `kjonn` og 
`sjukehus` er tilleggsvariablar som ein fjernar før bruk av 
`lag_valideringsdatasett()`. Dette gjer ein enkelt på følgjande måte: 

```{r fjern tilleggsvariablar}
d_reg = select(d_reg_full, -kjonn, -sjukehus)
```

```{r, echo = FALSE}
lag_kable(d_reg)
```

Når det er gjort er ein klar til å laga valideringsdatasettet.

### Komplett valideringsdatasett

Når ein køyrer `lag_valideringsdatasett()` får ein ut eit komplett 
valideringsdatasett, dersom ein ikkje har gjort ei filtrering av 
registerdatasettet på førehand. Eit komplett valideringsdatasett vil seie at 
alle variablar for alle pasientar/forløp er med. Talet på rader i 
valideringsdatasettet vert då lik talet på rader i det opphavlege datasettet 
gongar talet på datavariablar. For eksempelet over, med 5 rader og 8 
*datavariablar*, får ein eit valideringsdatasett med 40 rader:

```{r lag eksempel valideringsdatasett}
indvars = c("pasid", "dato_inn")
d_vld = d_reg %>%
  lag_valideringsdatasett(indvars)
```

```{r eksempel valideringsdatasett, echo = FALSE}
d_vld %>%
  lag_kable()
```

Det er likevel ofte at ein ikkje ynskjer eit komplett valideringsdatasett, 
med alle variablar for alle pasientar/forløp. Kanskje ein ynskjer å avgrensa
til eit visst antal rader, berre nokre visse sjukehus eller liknande. Under
er eksempel på fleire scenario og korleis ein kan gå fram skildra.


### Korleis lagra til SPSS-format?

For å lagra valideringsdatasettet som SPSS-format kan ein bruka `write_sav()` 
frå `haven`-pakken:

```{r eval=FALSE}
# Definerer og eventuelt lagar mappe for lagring
mappe = "H:\\Valideringsdata"
dir.create(mappe, showWarnings = FALSE, recursive = TRUE)

# Lagar filnamn og -adresse
filadresse = paste0(mappe, "\\valideringsdatasett.sav")

# Lagrar fila på SPSS-format
haven::write_sav(d_vld, filadresse)
```

#### Éi fil per sjukehus

Ofte vil det vera føremålstenleg å ha ei eiga fil for kvart sjukehus. Då må ein 
fyrst kopla på igjen kolonnen som seier kva sjukehus rada gjeld for. Korleis 
ein kan gjera dette er forklart i avsnitt xxx. Her tek me utgangspunkt i 
`d_vld_metadata`, definert i same avsnitt, for eit eksempel på å lagra éi fil
per sjukehus:

```{r eval=FALSE}
# Splittar valideringsdatasettet per sjukehus
d_vld_gruppert = group_by(d_vld_metadata, sjukehus)
sjukehus_namn = group_keys(d_vld_gruppert)[[1]]
d_vld_splitta = d_vld_gruppert %>%
  group_split()

# Lagar filadresse per sjukehus
filadresser = paste0(mappe, "\\", sjukehus_namn, ".sav")

# Lagrar filer på SPSS-format
purrr::pwalk(
  list(
    data = d_vld_splitta,
    path = filadresser
  ),
  haven::write_sav
)
```

### Utval av variablar

Dersom ein berre skal sjå på eit utval av variablane, kan ein gjera dette ved
å fjerna variablane som ikkje skal vera med, før ein kallar 
`lag_valideringsdatasett()`. Dette kan ein gjera på same måte som ein fjernar 
tilleggsvariablar:

```{r fjern variabel}
d_vld_fjern = d_reg %>%
  select(-dato_ut) %>%
  lag_valideringsdatasett(indvars)
```

```{r, echo = FALSE}
lag_kable(d_vld_fjern)
```

Eventuelt kan ein gjera det motsett, og velja dei variablane som *skal* vera 
med, dersom det er enklare. Då må ein hugsa på å også ta med indeksvariablane:

```{r vel ut variablar}
d_vld_fjern2 = d_reg %>%
  select(pasid, dato_inn, vekt, hogd) %>%
  lag_valideringsdatasett(indvars)
```

```{r, echo = FALSE}
lag_kable(d_vld_fjern2)
```

#### Bruk av logikk til å fjerna unødvendige rader

Det finst eksempel på at visse variablar berre gjev meining å sjekka dersom 
ein annan variabel har ein viss verdi. Det kan til dømes vera at ein har 
variabelen gravid, som berre gjev meining å sjekka dersom kjønn er kvinne. 
Slike rader kan ein fjerna frå valideringsdatasettet på denne måten:

```{r fjern rader med logikk}
# Lagar ein tabell med indeksvariablar og kjønn
d_kjonn = d_reg_full %>%
  select(pasid, dato_inn, kjonn)

# Koplar tabellen med kjønn på valideringsdatasettet
d_vld_med_kjonn = d_vld %>%
  left_join(d_kjonn, by = c("pasid", "dato_inn"))

# Filtrerer vekk unødvendige rader
d_vld_logikk = d_vld_med_kjonn %>%
  filter(!(kjonn == "M" & vld_varnamn == "gravid"))
```

```{r, echo = FALSE}
lag_kable(d_vld_logikk)
```

### Utval av visse variabelverdiar

Ein kan avgrense uttrekket til visse verdiar for éin eller fleire variablar,
til dømes dersom ein berre skal kontrollera data på eitt eller fleire 
særskilde sjukehus. Dette kan gjerast ved å starta med å filtrera på ynskja 
verdiar:

```{r filtrer sjukehus}
d_vld_bergen = d_reg_full %>%
  filter(sjukehus == "Bergen") %>%
  select(-kjonn, -sjukehus) %>%
  lag_valideringsdatasett(indvars)
```

```{r, echo = FALSE}
lag_kable(d_vld_bergen)
```

### Ymse typar tilfeldige utval

statistisk kommentar? eller berre la det stå i førre kapittel?

20 % av forløpa per variabel

Stadig meir vanskelege/avanserte eksempel

joining med andre datasett

stikkord:

- tilfeldig rekkjefølgje (*alle* rader)
- sample_n()
- sample_frac()
- per variabel?
- per pasient?
- sjå kommentarar lenger ned i vignetten for ulike eksempel (lag éi overskrift per eksempel)

#### Tilfeldig utval av n rader

For å trekkja ut n tilfeldige rader køyrer ein følgjande kode med
valideringsdatasettet `d_vld`:

```{r n rader}
n = 4
d_vld_n = sample_n(d_vld, n)
```

```{r, echo = FALSE}
lag_kable(d_vld_n)
```

#### Tilfeldig utval av andel av rader

For å trekkja ut x andel tilfeldige rader køyrer ein følgjande kode med
valideringsdatasettet`d_vld`:

```{r andel rader}
x = 0.15
d_vld_frac = sample_frac(d_vld, x)
```

```{r, echo = FALSE}
lag_kable(d_vld_frac)
```

#### Komplett valideringsdatasett i tilfeldig rekkjefølgje

Det kan vera ynskjeleg å bruka eit komplett valideringsdatasett i 
korrektheitsstudien, slik at ein jobbar seg gjennom så mykje ein klarar på 
ei gitt tid, men då i tilfeldig rekkjefølgje, slik at ein får eit tilfeldig 
utval. For å få til dette køyrer ein følgjande kode med valideringsdatasettet 
`d_vld`:

```{r tilfeldig rekkjefølgje}
d_vld_tilfeldig = sample_frac(d_vld)
```

```{r, echo = FALSE}
lag_kable(d_vld_tilfeldig)
```

#### Komplett valideringsdatasett med pasientar i tilfeldig rekkjefølgje

Dersom det er lite føremålstenleg å ha rader for same pasient på ulike stadar
i valideringsdatasettet kan ein trekkja alle pasientane i tilfeldig rekkjefølgje
og så ta med alle variablane for kvar pasient etter kvarandre. Dette kan gjerast 
ved å køyra følgjande kode med valideringsdatasettet `d_vld`:

```{r pasientar tilfeldig rekkjefølgje}
rekkjefolgje = sample(unique(d_vld$pasid))
d_vld_tilfeldig_pas = arrange(d_vld, match(pasid, rekkjefolgje), dato_inn)
```

```{r, echo = FALSE}
lag_kable(d_vld_tilfeldig_pas)
```

#### Tilfeldig utval av n forløp eller pasientar

For å trekkja ut n tilfeldige forløp køyrer ein følgjande kode med registerdata
`d_reg` og valideringsdatasettet`d_vld`:

```{r n forløp}
n = 1
uttrekk_forlop = select(d_reg, pasid, dato_inn) %>% # pasid og dato_inn er indeksvariablane
  # bruk berre pasid dersom det skal veljast ut
  # pasientar og ikkje forløp
  sample_n(n)

d_vld_n_forlop = semi_join(d_vld, uttrekk_forlop)
```

```{r, echo = FALSE}
lag_kable(d_vld_n_forlop)
```

#### Tilfeldig utval av k variablar, og så tilfeldig utval av m forløp per variabel

```{r k variablar m forløp}
k = 2
m = 2
uttrekk_variablar = sample(unique(d_vld$vld_varnamn), k)
d_vld_var_forlop = d_vld[c(), ]
for (variabel in uttrekk_variablar) {
  d_variabel = filter(d_vld, vld_varnamn == variabel)
  uttrekk_forlop = select(d_variabel, pasid, dato_inn) %>%
    sample_n(m)
  uttrekk_variabel = semi_join(d_variabel, uttrekk_forlop)
  d_vld_var_forlop = add_row(d_vld_var_forlop, uttrekk_variabel)
}
```

```{r, echo = FALSE}
lag_kable(d_vld_var_forlop)
```

#### Prioritering av visse variabelverdiar

I nokre tilfelle ynskjer ein å prioritera pasientar/forløp med visse 
variabelverdiar, som til dømes ein viss diagnose. I eksempelregisteret vårt
kan det tenkjast at ein vil prioritera pasientar med verdien `TRUE` på 
`biverk_hovud`. I vårt enkle eksempel kan ein til dømes trekkja ut 2 tilfeldige 
forløp med verdien `TRUE` på `biverk_hovud`, og 20 % blant resten. Dette kan 
gjerast fylgjande måte:

```{r prioritering variabelverdi}
d1 = filter(d_reg, biverk_hovud == TRUE)
d2 = setdiff(d_reg, d1)
d1_uttrekk = sample_n(d1, size = 2)
d2_uttrekk = sample_frac(d2, size = .2)
d_vld_prioritert = bind_rows(d1_uttrekk, d2_uttrekk) %>%
  lag_valideringsdatasett(indvars)
```

```{r, echo = FALSE}
lag_kable(d_vld_prioritert)
```

#### Samanhengande variablar

Visse variablar kan vera samanhengande ved at dei liknar eller er avhengig av 
kvarandre, som til dømes biverknadvariablane i eksempelregisteret vårt. Det 
kan vera føremålstenleg å inkludera alle slike samanhengande variablar for 
kvart forløp det éin eller fleire av dei er trekt ut, her har me teke 
utgangspunkt i `d_vld_n`:

```{r samanhengande variablar}
pasientar_biverk = d_vld_n %>%
  filter(vld_varnamn %in% c("biverk", "biverk_hovud", "biverk_mage", "biverk_fot")) %>%
  distinct(pasid, dato_inn)

d_pasientar_biverk = d_vld %>%
  filter(vld_varnamn %in% c("biverk", "biverk_hovud", "biverk_mage", "biverk_fot")) %>%
  right_join(pasientar_biverk, by = c("pasid", "dato_inn"))

d_vld_n_med_biverk = full_join(d_vld_n, d_pasientar_biverk, by = names(d_vld_n))
```

```{r, echo = FALSE}
lag_kable(d_vld_n_med_biverk)
```

### Fornuftig rekkjefølgje

Etter at ein har gjort eit tilfeldig utval kan det vera føremålstenleg å ha 
radene i ei fornuftig rekkjefølgje. Under er det vist nokre eksempel på 
sortering med utgangspunkt i `d_vld_n_med_biverk`.

#### Sorter rader etter forløp

```{r sorter forløp}
d_vld_sort_forlop = arrange(d_vld_n_med_biverk, pasid, dato_inn)
```

```{r, echo = FALSE}
lag_kable(d_vld_sort_forlop)
```

#### Sorter rader etter variablar

```{r sorter variablar}
var_rekkjefolgje = c(
  "dato_ut", "vekt", "hogd", "biverk",
  "biverk_hovud", "biverk_mage", "biverk_fot", "gravid"
)
d_vld_sort_var = arrange(d_vld_n_med_biverk, match(vld_varnamn, var_rekkjefolgje))
```

```{r, echo = FALSE}
lag_kable(d_vld_sort_var)
```

#### Sorter rader etter forløp og variablar

```{r sorter forløp og variablar}
d_vld_sort_forlop_var = d_vld_n_med_biverk %>%
  arrange(pasid, dato_inn, match(vld_varnamn, var_rekkjefolgje))
```

```{r, echo = FALSE}
lag_kable(d_vld_sort_forlop_var)
```

### Ekstra kolonnar med informasjon

Det kan vera nyttig å leggja til ekstra kolonnar i valideringsdatasettet, til 
dømes metadata som fødselsdato, alder og kjønn som kan gjera det enklare å
finna pasienten i pasientjournalen. Dette kan gjerast ved å kopla på igjen 
kolonnar frå registerdatasettet på valideringsdatasettet:

```{r legg til metadata}
d_reg_metadata = select(d_reg_full, pasid, dato_inn, kjonn, sjukehus)
d_vld_metadata = d_reg_metadata %>%
  inner_join(d_vld, by = c("pasid", "dato_inn"))
```

```{r, echo = FALSE}
lag_kable(d_vld_metadata)
```



## Statistiske avspekt ved bruk av valideringsdata

**Fixme:**
Her må det stå om viktige statistiske ting ein må vera klar over
når ein tolkar resultata frå valideringsdatasett.
Det gjeld både sjølve estimata og tilhøyrande konfidensintervall.
Bør òg vera vera eksempel på korleis ein får *riktige* estimat
på det ein er på jakt etter, ved for eksempel å ta vekta snitt
av estimata av ting samla inn gjennom stratifisert datainnsamling.
(Teksten som står her er berre kladd og spreidde tankar.
Må få skikkeleg introduksjon og god struktur.)

Total korrektheit:
(Fixme: Legg til referanse til dette i tihøyrande avsnitt.)
Statistikken, inkludert konfidensintervalla, er naturlegvis
berre gyldig dersom radene i valideringsdatasettet er eit
*tilfeldig utval* av alle verdiane registrert i registeret,
altså viss alle målingar har like stort sannsyn for å vera
med i valideringsanalysen.

Per variabel/sjukehus:
(Fixme: Legg til referanse til dette i tihøyrande avsnitt.)
Her er statistikken gyldig dersom det for kvar variabel er slik
at radene i valideringsdatasettet svarar til eit tilfeldig utval
av verdiane til tilhøyrande variabel i registeret. Men ein treng
ikkje ha like mange verdiar for kvar variabel, og ein kan for eksempel
validera fleire verdiar for viktige variablar enn for uviktige.
Men merk at då er ikkje lenger statistikken for total korrektheit
forventingsrett, og konfidensintervalla der kan ikkje brukast.
(Ev. flytta dette avsnittet seinare, og berre så vidt hinta om det her.)



<!-- Behovskartlegging

*I funksjonen bør det legges til mulighet for å hente ut et visst antall pasienter i utvalget (nå tas uansett alle sammen med per SPSS-fil, som er uoverkommelig for mange registre).
-> sample_frac() elns.

*Vi trenger altså en fil for hvert av de 6 angitte sykehusene, med f.eks. 100 pasienter med de 4 diagnosegruppene.
-> funksjon for lagring()???

*Viktig at RA-pasienter med diagnose 2014 eller seinere prioriteres (minst 50 pasienter der det finnes).
-> potensielt statistisk problematisk? viss sannsynet for å trekkast ut er avhengig av nokre variabelverdiar, for eksempel diagnose. uproblematisk ved *stratifisert* analyse eller ved rett justering.
-> d1 = filter(diag == "ra")
    d2 = filter(diag != "ra") ## antar ingen NA-ar
    d1_utval = sample_n(d1, n = 50)
    d2_utval = sample_frac(d2, frac = .2)
    d_utval = bind_rows(d1_utval, d2_utval)
    ## (i staden for d_utval = sample_frac(d, frac = .2)

*Når det gjelder diagnose og diagnosedato skal vi ikke undersøke om disse er korrekt registrert, for her er det mye skjønn og det er OK. Vi trenger dette til å se på en del av de senere punktene. Derfor ønsker vi at diagnose og diagnosedato som er registrert i NorArtritt skal ligge i filen som vi skal fylle inn slik at vi kan sammenholde.
For de andre variablene trenger vi ikke å ha NorArtritt dataene i filen."
-> left_join(d_utval, select(d_regdata, utvalde_kolonnar, ...))

*1) Hvis de henter tilfeldige variabler per pasient, ala SOReg-løsningen, kunne det vært slik at hvis en variabel som ble plukket ut var fra et sett med lignende variabler, så ble alle variablene i settet hentet for pasienten (eksemepelet var en rekke avkrysningsbokser for symptomer - hvis en variabel for et symptom, la oss si hodepine, blir trukket ut av variabel-rouletten, så ville de at variabelen for kvalme, kløe og fotsopp også ble med på den pasienten)
-> d_utval %>%
  left_join(d_regdata) %>%
  group_by(pasid) %>%
  filter(!(variabel1 != x, varnamn %in% c(variabel2, variabel3 osv.))) ## noko sånt ... :9

*2) At man hadde logikker med, at hvis pasienten har verdien er mann = ja så får ikke denne pasienten variabelen for graviditet med i sitt variabelsett. SOReg ville ha noe lignende - at man ikke fikk variabelen for 6 vekers vekt når pasienten fikk operasjonen sin i går.
-> d_vld_med_md %>%
  filter(!(kjonn="mann" && varnamn == "gravid))

*Tilfeldig utval av n pasientar.
-> 
  akt_pasientar = select(d_regdata, pasid, dato_inn) %>%
    ## ev. distinct() %>% ## viss det er pasientar og ikkje forløp me vil ha
    sample_n(n) %>%
  semi_join(d_utval, akt_pasientar)

*Tilfeldig utval av k variablar, og så tilfeldig utval av m pasientar per variabel.
->
  akt_variablar = sample(d_utval$varnamn, k)
  filter(d_utval, varnamn %in% akt_variablar)

*Variablane skal visast i ei fornuftig rekkjefølgje (sortert etter pasient,
eller etter ei spesiell variabelrekkjefølgje)
->
  ## Pasientar
  arrange(d_utval, pasid, dato_inn)

  ## Variabel
  var_rekkjefolgje = c("hogd", "vekt", "dato_ut")
  arrange(d_utval, !!match(varnamn, var_rekkjefolgje)) ## ??? Noko sånt, jaffal
  ## Men det lettaste er å ha variablane i god rekkjefolgje i utgangspunktet

Ev. annan funksjonalitet i opphavleg funksjon?
->
  ?
  
  Frå https://www.kvalitetsregistre.no/sites/default/files/2021-02/Erfaringer%20med%20valideringsstudie%20for%20SOReg-N.pdf finn me følgjande eksempel:
  
*«Registeret ble enige med
statistikerne om å trekke et overkommelig antall, tilfeldige variabler
per operasjon (operasjon = omtrent det samme som pasient, men
noen få pasienter hadde hatt reoperasjoner). Planen var i
utgangspunktet 7 tilfeldige variabler per operasjon.
[...] En erfaring var at å finne mange variabler for en pasient var lettere
enn å åpne ny journal for å finne verdiene til en ny pasient. På bakgrunn av
dette økte en antall tilfeldige valgte variabler til 10 variabler per pasient.»
Bør ha eksempel på korleis ein gjer dette.

*Eksempel på at ein legg til ekstra metadata (eks. fødselsdato, alder og kjønn)
for å lettare finna pasienten i pasientjournalen.

*Eksempel på variabelrekkjefølgje:

*«Rekkefølgene på radene var basert på en «naturlig» rekkefølge (for
eksempel kom baseline-variabler før oppfølgingsvariabler), slik at det
skulle være enklere og raskere å finne frem til informasjonen i
pasientjournalen.»

Eksempel på:

*«Videre viste det seg at mange av variablene var uaktuelle for enkelte pasienter.
Det var ikke aktuelt å se på 1-års-vekt til pasienter som nylig hadde hatt sin
operasjon og 1-års-oppfølging ikke var aktuelt enda. På bakgrunn av dette
kunne statistikere legge til i datasettet at variabler som gjaldt målinger på 6-
ukers og 1-års oppfølging bare dukket opp for pasienter som var aktuelle for
disse oppfølgingene.»

Eige kapittel om statistikk, med råd om å bruka survey-pakken
og lesa ei survey-boka. Og SSBs notat som ulike samplingsmåtar?

  
  Laging av eigne samanlikningfunksjonar (eiga avansert-kapittel).
  Og så må det stå om korleis standard samanlikningsfunksjon fungerer
  (spesielt om korleis handterer NA-verdiar).
  
Frå NORIC og AblaNor:
Me ønsker 
*-	at det skal vera mogleg å bestemma kva variabler som skal kontrollerast (til dømes dersom me veit at det er mykje feil i nokre felt vil me heller kontrollera dei felta enn tilfeldig utvalde variablar)
*-	å kunne avgrensa kor mange variabler som skal trekkjast ut + antal pasientar (Dersom prosjektet vert for stort er det vanskelig å finna ressursane til å gjennomføra det)
*-	at det er mogleg å avgrensa til utvalde sjukehus. (Til dømes dersom me veit at det er mykje feil i Stavanger kan me ha mål om å forbetra kvaliteten på innregistreringa der)
-	ein mal på korleis ein skal registrera samanlikningane ein gjer (Excel ark ein kan fylla inn i? Eller anna løysing? )
-	ein mal/døme på ferdig rapport. Til dømes flytskjema, oppteljingar per pasient/variabel med andel like/ulike registreringar, figurar 
-	gjerne ein halvautomatisert rapport. Me bruker rmd-format og tykkjer det fungerer fint. Kanskje ei rmd-fil me kan fylla parametre inn i kunne vore ein ide? Til dømes at me får første og siste registrering, dato for rapport, figurar, tabellar, overskrifter osv., så fyller me sjølve inn tekst og kompletterer ved behov. 

Sjå tekst og lenkjer på https://www.kvalitetsregistre.no/korrekthet
Verdt å merka seg:
*«For kontinuerlige variabler (eksempelvis høyde eller vekt) bør man også
analysere hvor stort avviket er fra den sanne verdien. En variabel hvor
avviket fra gullstandarden er stort er mer problematisk enn hvor
avviket er lite.»
Funksjon for å laga KI-variabel for kontinuerlege variablar?
Absoluttavvik (standard) eller avvik med forteikn?
  
-->
