---
title: "Ekstern validering"
author: "Per Erik Haugedal og Karl Ove Hufthammer"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Ekstern validering}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r pakkelasting, include = FALSE}
suppressPackageStartupMessages({
  library(rapwhale)
  library(tidyverse)
  library(kableExtra)
})
```

```{r kable-format, include = FALSE}
lag_kable = function(d, full_width = FALSE, ...) {
  d %>%
    kbl() %>%
    kable_styling("hover", full_width = full_width, ...)
}
```

```{css, echo=FALSE}
/* Hack for å få tabellar til å flyt ut i margen om nødvendig
   (fixme: bør erstattast med eit felles, eksternt og
           gjennomtenkt stilsett for alle vignettane) */
table { float: left; }
p, h1, h2, h3, h4, h5, h6, div {
  clear: both;
}
```


## Innleiing

I `rapwhale` finst ein infrastruktur – eit sett R-funksjonar og tilhøyrande
metodikk – for *ekstern validering* av registerdata. Målet med denne
har vore å gjera det enklare, raskare og sikrare å gjennomføra ekstern
validering av høg kvalitet.

*Ekstern validering* går her ut på å finna ut om dataa i registeret er 
lik dataa i ein gitt gullstandard, typisk ein pasientjournal.
For meir informasjon, sjå
[SKDE sin artikkel om korrektheit](https://www.kvalitetsregistre.no/korrekthet).

Me har laga eit standardisert format for valideringsdata og
eit sett R-funksjonar for å analysera og laga datasett på dette formatet.
La oss først sjå nærare på formatet me har komme fram til.


## Format til valideringsdatasett

I eit valideringsdatsett må me for kvar måling
(for eksempel vekta eller høgda til ein person)
registrera verdien av målinga i registeret (*intern verdi*) og
tilhøyrande verdi i den eksterne kjelda (*ekstern verdi*), gullstandarden.
I tillegg treng me informasjon om kva pasient eller forløp
verdien gjeld samt kva for variabel det er snakk om.

### Første forsøk på eit format

I utgangspunktet verkar eit format som dette fornuftig:

```{r superenkelt eksempel, echo = FALSE}
d_banalt = tibble::tribble(
  ~pasid, ~varnamn, ~verdi_intern, ~verdi_ekstern,
  5, "vekt", 78, 78,
  7, "vekt", 53, 53,
  7, "hogd", 196, 186
)
lag_kable(d_banalt)
```

Her kan me registrera høgda og vekta til kvar pasient
(identifisert med pasient-ID, `pasid`),
både internt i registeret og i den eksterne kjelda.

Men for meir realistiske datasett støyter me fort på problem,
som me har løyst med eit utvida og endeleg format.


### Utvida og endeleg format

Det er tre potensielle problem –
at ein pasient kan ha *fleire målingar* av same variabel,
at me kan ha målingar av *ulike datatypar* (eksempelvis både tal og datoar)
og at indeksvariablar kan ha *same namn* som verdivariablane.

Ein pasient kan ha *fleire målingar* av same variabel
dersom han vore til fleire undersøkingar.
Det løyser me enkelt ved å tillata fleire *indeksvariablar*,
for eksempel både pasient-ID og undersøkingsdato.
Dette er variablar som saman med `vld_varnamn` unikt identifiserer kvar måling.
(Det svarar altså til *primærnøklar* i databasar.)

Eit register har vanlegvis målingar av *ulike datatypar*,
for eksempel både tal (som ovanfor) og datoar eller logiske variablar
(`TRUE`/`FALSE`).
Men i dei fleste datasystem kan ein kolonne berre innehalda data av éin type.
Dette løyser me ved å innføra fleire verdikolonnar,
éin for kvar datatype.
Me treng då òg ein kolonne (`vld_vartype`) som seier kva type variabel
som kvar verdi gjeld.

I sjeldne tilfelle har indeksvariablar *same namn* som verdivariablane.
Det prøver me å løysa ved at alle variablar utanom indeksvariablane
får prefikset *vld_* («validering»).
Dette vert då å rekna som eit reservert prefiks.

I det endelege formatet er det framleis slik at kvar rad
indentifiserer ei *måling* (med to verdiar, éin intern og éin ekstern):

```{r eksempel format, echo = FALSE}
d_vld = tibble::tribble(
  ~pasid, ~dato_inn, ~vld_varnamn, ~vld_vartype, ~vld_verdi_intern_dato, ~vld_verdi_ekstern_dato, ~vld_verdi_intern_tal, ~vld_verdi_ekstern_tal,
  5, as.Date("2020-06-07"), "vekt", "tal", NA, NA, 78, 78,
  5, as.Date("2020-06-07"), "dato_ut", "dato", as.Date("2020-06-15"), as.Date("2020-06-15"), NA, NA,
  5, as.Date("2020-12-13"), "vekt", "tal", NA, NA, NA, NA,
  5, as.Date("2020-12-13"), "dato_ut", "dato", as.Date("2020-12-13"), as.Date("2020-12-14"), NA, NA,
  7, as.Date("2020-08-07"), "vekt", "tal", NA, NA, 53, 53,
  7, as.Date("2020-08-09"), "hogd", "tal", NA, NA, 196, 194,
  7, as.Date("2020-08-09"), "dato_ut", "dato", as.Date("2020-08-13"), as.Date("2020-08-13"), NA, NA
)
lag_kable(d_vld)
```

Her utgjer `pasid` (pasient-ID) og `dato_inn` (innskrivingsdato)
indeksvariablane som *saman* unikt identifiserer ei måling (rad).
Pasient 5 har hatt to opphald og pasient 7 eitt.
(På det andre opphaldet til pasient 5 hadde ein gløymt å vega pasienten.)
Me vil samanlikna kva verdiar dei tre variablane
`vekt` (vekta til pasienten),
`hogd` (høgda til pasienten)
og `dato_ut` (utskrivingsdatoen for pasienten)
har i registeret med tilhøyrande verdiar i den eksterne kjelda.


## Bruk av valideringsdatasett

Når me har eit ferdig utfylt valideringsdatsett,
er det svært lett å samananlikna dei interne og eksterne verdiane.
Så kan me rekna ut statistikk som seier kor korrekte dataa er,
og til slutt kan me bruka statistikken i tabellar og
figurar i valideringsrapportar.


### Samanlikning av interne og eksterne verdiar

Til å samanlikna verdiane brukar me `analyser_valideringsdatasett()`:

```{r samanlikning}
d_samanlikna = d_vld %>%
  analyser_valideringsdatasett()
```

```{r, echo = FALSE}
lag_kable(d_samanlikna)
```

Den nye kolonnen `ki_krit_teller` seier om dei interne og
dei eksterne verdiane er *like*.
Merk at to `NA`-verdiar som standard vert rekna som like
(noko som ikkje er vanleg i R).
Tanken bak dette er at om for eksempel `vekt` ikkje er registrert i registeret,
så *skal* heller ikkje vektinformasjon finnast i pasientjournalen,
og vice versa.

Men dersom gullstandarden og registeret ikkje har same *kjelde* til data,
for eksempel viss me samanliknar pasient- og legerapporterte data,
kan me ynskja eit visst slingringsmonn ved samanlikningane.
Me kan for eksempel ynskja at måling av vekt skal ha eit slingringsmonn
på 4 (kg), måling av høgd skal ha eit slingringsmonn på 2 (cm),
men operasjonsdatoen må vera heilt nøyaktig.
Dette kan ein få til ved å laga eigne *samanliknarfunksjonar*
(argumentet `samanliknar`).
Sjå meir om samanliknarfunksjonar i avsnitt **fixme**.



### Utrekning av korrektheitsstatistikk

Som vist ovanfor, legg `analyser_valideringsdatasett()` til *to* kolonnar,
`ki_krit_teller`, som me alt har sett på,
og `ki_krit_nevner`, som er `TRUE` for alle radene.
I praksis lagar me ein altså eit formelt kvalitetsindikator-datasett
(sjå **fixme: lenkje til vignett om kvalitetsindikatorar**),
noko som gjer at me kan bruka `aggreger_ki_prop()`
for å rekna ut korrektheitstatistikk,
både totalt og stratifisert på éin eller fleire variablar.


#### Total korrektheit

Total korrektheit reknar me ut direkte med `aggreger_ki_prop()`:

```{r aggregering total}
d_samanlikna %>%
  aggreger_ki_prop()
```

```{r, include=FALSE}
# Hack for å kunna ha tilgang til resultata i teksten
# utan å laga eksplisitt variabelnamn i eksempelet
d_agg_total = aggreger_ki_prop(d_samanlikna)
```

Her ser me at `r d_agg_total$ki_teller` av `r d_agg_total$ki_nevner`
(dvs. `r round(100*d_agg_total$est)` %)
av verdiane var like i registeret og gullstandarden.
Me får òg ut tilhøyrande 95 %-konfidensintervall.


#### Korrektheit per variabel

Nokre variablar er gjerne oftare korrekt registrerte enn andre.
Me kan lett få ut stratifisert statistikk ved å bruka `group_by()`:

```{r aggregering per-variabel}
d_samanlikna %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()
```

Tilsvarande kan me rekna ut korrektheit per sjukehus,
per variabel per sjukehus,
eller over tid (ved å ha år og månad som grupperingsvariablar).


#### Bruk av statistikken

Til slutt kan me visa statistikken i fine tabellar og figurar.
Her er eit komplett eksempel på bruk av eit valideringsdatasett,
med figur:

```{r, fig.width=5}
# Rekn ut korrektheit per variabel
d_korrektheit = d_vld %>%
  analyser_valideringsdatasett() %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()

# Eventuelt sorter for å få finare grafar og tabellar
d_korrektheit_sortert = d_korrektheit %>%
  arrange(est) %>%
  mutate(varnamn_sortert = forcats::fct_inorder(vld_varnamn))
# Brukte her arrange() for at resultatet lett skal kunna brukast
# i tabellar òg. Skal me berre laga grafar, kunne me heller bruka
# forcats::fct_reorder() direkte i mutate()-steget.
# I mutate()-steget kan me godt òg laga finare variabelnamn ...

# Enkel figur
library(ggplot2)
ggplot(
  d_korrektheit_sortert,
  aes(
    x = est, xmin = konfint_nedre, xmax = konfint_ovre,
    y = varnamn_sortert
  )
) +
  geom_pointrange() +
  scale_x_continuous(labels = scales::percent) +
  ggtitle("Korrektheit for utvalde variablar") +
  xlab("Korrekt") +
  ylab(NULL)
```

Her kan (og bør) me sjølvsagt finpussa figuren for å gjera
han meir brukarvennleg, men det er ikkje tema for denne vignetten.

Me tilrår elles òg *sterkt* å bruka SPC-metodikk,
*ikkje* konfidensintervall,
for samanlikning av korrektheit,
for eksempel mellom ulike sjukehus eller over tid,
men det er heller ikkje tema her.



## Generering av valideringsdatasett

Denne pakken har funksjonar for enkelt å laga klar valideringsdatasett.
Først treng me registerdata, lagra som eitt eller fleire datasett.
Så kan me bruka `lag_valideringsdatasett()` til å laga valideringsdatasett,
og til slutt kan me tilpassa dette datasettet slik at me
berre treng validera dei variablane og verdiane me er intersserte i.

### Eksempel på register

Me har eit enkelt register som registrerer vekt, høgd, om pasienten har opplevd
biverknadar, kva type biverknadar og om pasienten er gravid.
Nokre av variablane i registeret kan sjå slik ut:

```{r lageksempel, echo = FALSE}
d_reg_full = tibble::tribble(
  ~pasid, ~dato_inn, ~sjukehus, ~dato_ut, ~vekt, ~hogd, ~biverk, ~biverk_hovud, ~biverk_mage, ~biverk_fot, ~gravid,
  5, as.Date("2020-06-07"), "Bergen", as.Date("2020-06-15"), 78, 183, TRUE, FALSE, TRUE, TRUE, NA,
  5, as.Date("2020-12-13"), "Førde", as.Date("2020-12-13"), 50, 179, TRUE, FALSE, TRUE, TRUE, NA,
  7, as.Date("2020-08-09"), "Bergen", as.Date("2020-08-13"), 711, 196, TRUE, TRUE, TRUE, TRUE, TRUE,
  13, as.Date("2021-01-05"), "Førde", NA, NA, 163, FALSE, NA, NA, NA, NA,
  14, as.Date("2021-01-05"), "Førde", as.Date("2021-01-09"), 101, 182, TRUE, TRUE, FALSE, FALSE, NA
)
d_pas = tibble::tribble(
  ~pasid, ~kjonn,
  5, "mann",
  7, "kvinne",
  13, "mann",
  14, "mann"
)
lag_kable(d_reg_full)
```

I dette eksempelet er indeksvariablane `pasid` og `dato_inn`.
Sjukehus er alltid registrert rett,
så det er ein variabel me ikkje er interessert i å validera.
Me fjernar han derfor før me genererer valideringsdatasettet.

```{r fjern tilleggsvariablar}
d_reg = select(d_reg_full, -sjukehus)
```


### Komplett valideringsdatasett

Når me køyrer `lag_valideringsdatasett()`,
får me ut eit komplett valideringsdatasett,
der alle pasientar/forløp og alle datavariablar er med.
Talet på rader vert då lik talet på rader i det opphavlege datasettet 
gongar talet på datavariablar.
Her har me 5 pasientforløp og 8 *datavariablar*,
og me får såleis eit valideringsdatasett med 40 rader:

```{r lag eksempel valideringsdatasett}
d_vld = lag_valideringsdatasett(d_reg, indvars = c("pasid", "dato_inn"))
```

```{r eksempel valideringsdatasett, echo = FALSE}
d_vld %>%
  lag_kable()
```

For å ikkje få for breie tabellar
viser me berre nokre av kolonnane i dei vidare eksempla:

```{r}
d_vld_enkel = select(d_vld, pasid:vld_vartype)
```



### Tilfeldig rekkjefølgje og utval

Om me vil, kan me no validera *heile* datasettet
(ved å samanlikna det med gullstandraden).
Men i praksis vil me ta ein stikkprøve.

Kanskje har me berre tid til å validera ti målingar:

```{r}
set.seed(12345) # For reproduserbare «tilfeldige» trekkingar
slice_sample(d_vld_enkel, n = 10)
```

Eller ti prosent av datasettet:

```{r}
slice_sample(d_vld_enkel, prop = .1)
```

I nokre tilfelle kan me ikkje garantera tid til å
validera eit visst tal eller ein viss prosentdel av målingane.
Ei pragmatisk løysing er då gjera klar *heile* valideringsdatasettet,
men i tilfeldig rekkjefølgje.
Når me skal gjennomføra valideringa, startar me på toppen
og arbeider oss nedover.
Når me slepp opp for tid,
slettar me rett og slett dei resterande radene.
Me har likevel eit tilfeldig utval rader:

```{r}
slice_sample(d_vld_enkel, n = Inf)
```


### Valideringsdatasett med forløp i tilfeldig rekkjefølgje

Når me jamfører registerdata med for eksempel pasientjournalar,
er praktisk å sjå på alle datavariablane samla for kvar pasient,
slik at me ikkje heile tida må veksla mellom journalar.
Me har for eksempel fått denne stikkprøven med valideringsdata:

```{r}
d_vld_utval = d_vld_enkel[c(18, 32, 1, 40, 2, 17), ]
d_vld_utval
```

Her er ein enkel måte å samla dataa på,
men som samtidig sikrar
tilfeldig rekkjefølgje på pasientane (som er viktig for validiteten)

```{r}
set.seed(1) # For reproduserbare «tilfeldige» trekkingar
d_vld_utval_samla = d_vld_utval %>%
  group_by(pasid, dato_inn) %>% # Ev. bruk nest_by()
  nest() %>%
  ungroup() %>% # Nødvendig for slice_sample()
  slice_sample(n = Inf) %>%
  unnest(data)
d_vld_utval_samla
```

Viss me heller berre vil ha eit *utval* av forløpa,
endrar me berre `n`-verdien i `slice_sample()`.



### Variablar i fast rekkjefølgje

Det er gjerne praktisk at datavariablane kjem i same
rekkjefølgje for alle pasientane,
Det kan for eksempel vera rekkjefølgja opplysningane står
i i pasientjournalen.
Det ordnar me lett.

I dette eksempelet brukar me variabelrekkjefølgja
frå det opphavlege datasettet:

```{r}
var_rekkjefolgje = names(d_reg_full)
d_vld_utval %>%
  arrange(match(vld_varnamn, !!var_rekkjefolgje))
```

(Og så kan me bruka oppskrifta frå førre avsnitt for å få
dataa frå same pasient samla.)



### Tilfeldig utval av fast tal pasientar og variablar

Alt ovanfor kan sjølvsagt kombinerast.
Viss me vil trekkja 5 forløp og 2 variablar per forløp,
kan me gjera det slik:

```{r}
set.seed(1) # For reproduserbare «tilfeldige» trekkingar
n_forlop = 5 # Talet på forløp
n_var = 2 # Talet på variablar per forløp
d_vld_utval = d_vld_enkel %>%
  group_by(pasid, dato_inn) %>%
  slice_sample(n = n_var) %>%
  nest() %>%
  ungroup() %>% # Nødvendig for slice_sample()
  slice_sample(n = n_forlop) %>%
  unnest(data)
print(d_vld_utval, n = Inf) # 10 rader
```



### Utval av variablar i ferdige valideringsdatasett

Dersom ein berre skal sjå på eit utval av variablane,
kan me anten gjer dette *før* me lagar valideringsdatasettet
(slik me gjorde med `sjukehus`-variabelen)
eller ved filtrering etterpå.
Viss me for eksempel ikkje vil ha med biverknadsvariablane i
eit allereie laga valideringsdatasett,
kan me fjerna dei slik:

```{r fjern variabel}
d_vld %>%
  filter(!str_detect(vld_varnamn, "^biverk"))
```



#### Bruk av logikk til å fjerna unødvendige rader

Nokre variablar gjev berre meining å sjekka
dersom andre variablar har visse verdiar.
Variabelen `gravid` treng ein for eksempel berre sjekka
dersom pasienten er kvinne.

Merk at informasjon om kjønn ikkje finst i valideringsdatasettet,
så me hentar det frå eit anna datasett.
(Ein slik operasjon kan vera nyttig i mange samanhengar,
for eksempel for å hekta fødselsnummer på valideringsdatasett,
slik at det vert lettare å finna pasienten i pasientjournalen.)

```{r fjern rader med logikk}
# Koplar tabellen med kjønn på valideringsdatasettet
d_vld_med_kjonn = d_vld %>%
  left_join(d_pas, by = c("pasid"))

# Filtrerer vekk rader som gjeld graviditet for «ikkje-kvinner» (inkl. NA-kjønn)
d_vld_med_kjonn %>%
  filter(!(vld_varnamn == "gravid" & kjonn != "kvinne"))
```

Logikken kan sjølvsagt skrivast på mange (ekvivalente) måtar, for eksempel:

```{r}
d_vld_med_kjonn %>%
  filter(vld_varnamn != "gravid" | kjonn == "kvinne")
```

Men ein kan lett gå seg bort i alle `!`-teikna og parentesane som trengst
for å uttrykka seg.
Me tilrår derfor å bruka `impl()`-funksjonen i `rapwhale`,
som er ein enkel måte å uttrykka sanningsverdiane i utsegn på forma
«A impliserer B» (altså «viss A, så B»).
I vårt eksempel er logikken «viss me ser på gravidvariabelen,
så må det vera for ei kvinne»:

```{r}
d_vld_med_kjonn %>%
  filter(impl(vld_varnamn == "gravid", kjonn == "kvinne"))
```



#### Logikk basert på fleire variablar

I nokre tilfelle kan samanhengen mellom variablane vera meir kompleks.
For eksempel fyller ein ut biverknads-«undervariablane»
`biverk_hovud`, `biverk_mage` og `biverk_fot`
viss og berre viss hovudvariabelen `biverk` er `TRUE`.
Det har kanskje ikkje noko for seg å sjekka
`biverk_hovud` viss `biverk` er `FALSE`
(gitt at innregistreringssystemet garanterer at ein
ikkje kan registrera inkonsistente verdiar,
og gitt at `biverk` alltid er til å stola på).

Her lagar me først eit uttrekk på vanleg vis,
og så fjernar me dei radene som ikkje skal vera med:

```{r}
# Først eit utkast til valideringsdatasett, to variablar per forløp
set.seed(1)
d_vld_utval_utkast = d_vld %>%
  group_by(pasid, dato_inn) %>%
  slice_sample(n = 2)

# Legg til info om hovud-biverknadsvariabel og filtrer på denne
d_reg_biverk = select(d_reg, pasid, dato_inn, biverk)
varnamn_undervar = c("biverk_hovud", "biverk_mage", "biverk_fot")
d_vld_utval_endeleg = d_vld_utval_utkast %>%
  left_join(d_reg_biverk) %>%
  group_by(pasid, dato_inn) %>%
  filter(impl(vld_varnamn %in% !!varnamn_undervar, biverk))

# Talet på observasjonar i datasetta
nrow(d_vld_utval_utkast)
nrow(d_vld_utval_endeleg)
```


#### Logikk basert på faste variabelsett

Nokre gongar heng eit sett variablar så sterkt saman
at me vil sjå på / validera alle dersom me ser på minst éin av dei.
Viss me for eksempel for eit forløp skal validera variabelen for magebiverknadar,
vil me òg validera dei andre biverknadsvariablane, altså dei for
hovud- og fotbiverknadar samt den generelle biverknadsvariabelen.

Det er fleire måtar å få dette til på.
Her er eit eksempel der me
i staden for å bruka `slice_sample()` til å filtrera vekk rader *direkte*,
først lagar ein «inklusjonsvariabel» som seier om den aktuelle rada
skal takast med (inkluderast) i valideringsdatasettet.
Dette mogleggjer meir avansert vidarebehandling,
der verdien til inklusjonsvariabelen kan avhenga av fleire rader:

```{r samanhengande variablar}
# Viss minst éin av desse variablane inngår i valideringsdatasettet
# for eit forløp, så skal alle gjera det
varnamn_biverk = c("biverk", "biverk_hovud", "biverk_mage", "biverk_fot")

# Skal bruka indeksvariablane fleire gongar, så lagrar dei
# for enkelheits skuld som ein eigen variabel
indeksvar = quos(pasid, dato_inn)

set.seed(57)
d_vld_utval_utkast = d_vld_enkel %>%
  group_by(!!!indeksvar) %>%
  mutate(inkluder = row_number() %in% sample(row_number(), 2)) # To verdiar per forløp
filter(d_vld_utval_utkast, inkluder)

# Generell hjelpefunksjon for å oppdatera inklusjonsstatus,
# der denne vert sett til TRUE for alle variablane med namn
# i «varnamn_gruppe» dersom minst éin av dei har
# inklusjonsstatus TRUE. Er meint å køyrast på grupperte datasett.
oppdater_inklusjonsstatus = function(inkluder, vld_varnamn, varnamn_gruppe) {
  er_variabel_i_gruppa = vld_varnamn %in% varnamn_gruppe
  if (any(inkluder[er_variabel_i_gruppa])) {
    inkluder[er_variabel_i_gruppa] = TRUE
  }
  inkluder
}

# Ta med alle biverknadsrader dersom minst éi er teken med (per forløp)
d_vld_utval_utkast = d_vld_utval_utkast %>%
  group_by(!!!indeksvar) %>%
  mutate(inkluder = oppdater_inklusjonsstatus(inkluder, vld_varnamn, !!varnamn_biverk))

# Fjern alle ikkje-inkluderte rader
d_vld_utval_endeleg = d_vld_utval_utkast %>%
  filter(inkluder) %>%
  select(-inkluder)
print(d_vld_utval_endeleg, n = Inf)
```




## Lagring og lesing av valideringsdatasett

### Eigna filformat og dataprogram for utfylling

Formatet på valideringsdatasetta er utforma slik
at datasetta lett kan brukast i ulike dataprogram/filformat.
Ein står fritt til sjølv å velja kva filformat ein vil bruka
når ein skal fylla ut valideringsdatasetta
med verdiane frå den eksterne kjelda.

Me tilrår likevel sterkt å bruka anten eit databaseverktøy
eller eit statistikkprogram *som sikrar dataintegriteten*.
Programmet bør sikra at ein for eksempel ikkje ved ein feil
skriv inn tekst eller tal i ein kolonne som berre tek datoar.

Både SPSS og Stata er statistikkprogram som er godt eigna.
Me **frårår på det sterkaste** å bruka Microsoft Excel.
Me viser her eit par eksempel på korleis ein kan lagra
valideringsdatasettet vårt til SPSS-format.


### Fullstendig valideringsdatasett til SPSS-format

For å lagra valideringsdatasettet som SPSS-format kan me bruka `write_sav()` 
frå `haven`-pakken:

```{r eval=FALSE}
# Definerer mappe og filnamn for lagring
mappe_vld = "h:\\valideringsdata\\"
filnamn = "valideringsdatasett.sav"
filadresse = paste0(mappe_vld, filnamn)

# Opprett mappa (om ho ikkje finst frå før)
dir.create(mappe_vld, showWarnings = FALSE, recursive = TRUE)

# Lagra valideringsdatasett på SPSS-format
library(haven)
write_sav(d_vld, filadresse)
```

For lesing av ferdigredigerte valideringsfiler
brukar me tilsvarande `read_spss()`.


### Eitt valideringsdatasett per sjukehus til SPSS-format

Når me reiser rundt og validerer,
gjer me det jo for eitt og eitt sjukehus,
så ofte vil det vera føremålstenleg å ha éi fil per sjukehus.
Me har gjerne sjukehusinfo for kvart forløp lagra i eit separat datasett:

```{r, include=FALSE}
d_forlopsinfo = distinct(d_reg_full, pasid, dato_inn, sjukehus)
```

```{r}
d_forlopsinfo
```

Me må først kopla sjukehusnamna på valideringsdatasettet.
Me genererer så filnamn basert på desse namna.
For å få meir maskinvennlege filnamn brukar me i dette eksempelet
`to_any_case()`-funksjonen i `snakecase`-pakken.
(Slik me brukar han,
vil han for eksempel gjera om `"Helse Førde"` til `"helse_forde"`.)
Til slutt er det berre å dela opp valideringsdatasettet i eitt datasett
per sjukehus og lagra desse datasetta i separate filer:

```{r eval=FALSE}
# Hekt på sjukehusnamn
d_vld_med_sjukehus = d_vld %>%
  left_join(d_forlopsinfo, by = c("pasid", "dato_inn"))

# Generer maskinvennlege filadresser
library(snakecase)
d_vld_med_sjukehus = d_vld_med_sjukehus %>%
  mutate(
    filnamn = paste0(to_any_case(sjukehus, transliterations = "Latin-ASCII"), ".sav"),
    filadresse = paste0(mappe_vld, filnamn)
  )

# Del opp datasettet i eitt per sjukehus/filamn,
# og lagra dei som separate filer
d_vld_med_sjukehus %>%
  split(.$filadresse) %>%
  iwalk(write_sav)
```

Me kan bruka tilsvarande metodikk viss me vil ha éi fil
per årstal, per månad eller per sjukehus per månad.
Når me så har fylt ut valideringsdatasetta i SPSS,
kan me enkelt lasta dei alle inn *til eitt stort datasett* slik:

```{r eval = FALSE}
filadresser = list.files(mappe_vld, pattern = "\\.sav$", full.names = TRUE)
d_vld_utfylt = filadresser %>%
  map_dfr(read_sav)
```



## Statistiske avspekt ved bruk av valideringsdata

**Fixme:**
Her må det stå om viktige statistiske ting ein må vera klar over
når ein tolkar resultata frå valideringsdatasett.
Det gjeld både sjølve estimata og tilhøyrande konfidensintervall.
Bør òg vera vera eksempel på korleis ein får *riktige* estimat
på det ein er på jakt etter, ved for eksempel å ta vekta snitt
av estimata av ting samla inn gjennom stratifisert datainnsamling.
(Teksten som står her er berre kladd og spreidde tankar.
Må få skikkeleg introduksjon og god struktur.)

Total korrektheit:
(Fixme: Legg til referanse til dette i tihøyrande avsnitt.)
Statistikken, inkludert konfidensintervalla, er naturlegvis
berre gyldig dersom radene i valideringsdatasettet er eit
*tilfeldig utval* av alle verdiane registrert i registeret,
altså viss alle målingar har like stort sannsyn for å vera
med i valideringsanalysen.

Per variabel/sjukehus:
(Fixme: Legg til referanse til dette i tihøyrande avsnitt.)
Her er statistikken gyldig dersom det for kvar variabel er slik
at radene i valideringsdatasettet svarar til eit tilfeldig utval
av verdiane til tilhøyrande variabel i registeret. Men ein treng
ikkje ha like mange verdiar for kvar variabel, og ein kan for eksempel
validera fleire verdiar for viktige variablar enn for uviktige.
Men merk at då er ikkje lenger statistikken for total korrektheit
forventingsrett, og konfidensintervalla der kan ikkje brukast.
(Ev. flytta dette avsnittet seinare, og berre så vidt hinta om det her.)



<!-- Behovskartlegging

*I funksjonen bør det legges til mulighet for å hente ut et visst antall pasienter i utvalget (nå tas uansett alle sammen med per SPSS-fil, som er uoverkommelig for mange registre).
-> sample_frac() elns.

*Vi trenger altså en fil for hvert av de 6 angitte sykehusene, med f.eks. 100 pasienter med de 4 diagnosegruppene.
-> funksjon for lagring()???

*Viktig at RA-pasienter med diagnose 2014 eller seinere prioriteres (minst 50 pasienter der det finnes).
-> potensielt statistisk problematisk? viss sannsynet for å trekkast ut er avhengig av nokre variabelverdiar, for eksempel diagnose. uproblematisk ved *stratifisert* analyse eller ved rett justering.
-> d1 = filter(diag == "ra")
    d2 = filter(diag != "ra") ## antar ingen NA-ar
    d1_utval = sample_n(d1, n = 50)
    d2_utval = sample_frac(d2, frac = .2)
    d_utval = bind_rows(d1_utval, d2_utval)
    ## (i staden for d_utval = sample_frac(d, frac = .2)

*Når det gjelder diagnose og diagnosedato skal vi ikke undersøke om disse er korrekt registrert, for her er det mye skjønn og det er OK. Vi trenger dette til å se på en del av de senere punktene. Derfor ønsker vi at diagnose og diagnosedato som er registrert i NorArtritt skal ligge i filen som vi skal fylle inn slik at vi kan sammenholde.
For de andre variablene trenger vi ikke å ha NorArtritt dataene i filen."
-> left_join(d_utval, select(d_regdata, utvalde_kolonnar, ...))

*1) Hvis de henter tilfeldige variabler per pasient, ala SOReg-løsningen, kunne det vært slik at hvis en variabel som ble plukket ut var fra et sett med lignende variabler, så ble alle variablene i settet hentet for pasienten (eksemepelet var en rekke avkrysningsbokser for symptomer - hvis en variabel for et symptom, la oss si hodepine, blir trukket ut av variabel-rouletten, så ville de at variabelen for kvalme, kløe og fotsopp også ble med på den pasienten)
-> d_utval %>%
  left_join(d_regdata) %>%
  group_by(pasid) %>%
  filter(!(variabel1 != x, varnamn %in% c(variabel2, variabel3 osv.))) ## noko sånt ... :9

*2) At man hadde logikker med, at hvis pasienten har verdien er mann = ja så får ikke denne pasienten variabelen for graviditet med i sitt variabelsett. SOReg ville ha noe lignende - at man ikke fikk variabelen for 6 vekers vekt når pasienten fikk operasjonen sin i går.
-> d_vld_med_md %>%
  filter(!(kjonn="mann" && varnamn == "gravid))

*Tilfeldig utval av n pasientar.
-> 
  akt_pasientar = select(d_regdata, pasid, dato_inn) %>%
    ## ev. distinct() %>% ## viss det er pasientar og ikkje forløp me vil ha
    sample_n(n) %>%
  semi_join(d_utval, akt_pasientar)

*Tilfeldig utval av k variablar, og så tilfeldig utval av m pasientar per variabel.
->
  akt_variablar = sample(d_utval$varnamn, k)
  filter(d_utval, varnamn %in% akt_variablar)

*Variablane skal visast i ei fornuftig rekkjefølgje (sortert etter pasient,
eller etter ei spesiell variabelrekkjefølgje)
->
  ## Pasientar
  arrange(d_utval, pasid, dato_inn)

  ## Variabel
  var_rekkjefolgje = c("hogd", "vekt", "dato_ut")
  arrange(d_utval, !!match(varnamn, var_rekkjefolgje)) ## ??? Noko sånt, jaffal
  ## Men det lettaste er å ha variablane i god rekkjefolgje i utgangspunktet

Ev. annan funksjonalitet i opphavleg funksjon?
->
  ?
  
  Frå https://www.kvalitetsregistre.no/sites/default/files/2021-02/Erfaringer%20med%20valideringsstudie%20for%20SOReg-N.pdf finn me følgjande eksempel:
  
*«Registeret ble enige med
statistikerne om å trekke et overkommelig antall, tilfeldige variabler
per operasjon (operasjon = omtrent det samme som pasient, men
noen få pasienter hadde hatt reoperasjoner). Planen var i
utgangspunktet 7 tilfeldige variabler per operasjon.
[...] En erfaring var at å finne mange variabler for en pasient var lettere
enn å åpne ny journal for å finne verdiene til en ny pasient. På bakgrunn av
dette økte en antall tilfeldige valgte variabler til 10 variabler per pasient.»
Bør ha eksempel på korleis ein gjer dette.

*Eksempel på at ein legg til ekstra metadata (eks. fødselsdato, alder og kjønn)
for å lettare finna pasienten i pasientjournalen.

*Eksempel på variabelrekkjefølgje:

*«Rekkefølgene på radene var basert på en «naturlig» rekkefølge (for
eksempel kom baseline-variabler før oppfølgingsvariabler), slik at det
skulle være enklere og raskere å finne frem til informasjonen i
pasientjournalen.»

Eksempel på:

*«Videre viste det seg at mange av variablene var uaktuelle for enkelte pasienter.
Det var ikke aktuelt å se på 1-års-vekt til pasienter som nylig hadde hatt sin
operasjon og 1-års-oppfølging ikke var aktuelt enda. På bakgrunn av dette
kunne statistikere legge til i datasettet at variabler som gjaldt målinger på 6-
ukers og 1-års oppfølging bare dukket opp for pasienter som var aktuelle for
disse oppfølgingene.»

Eige kapittel om statistikk, med råd om å bruka survey-pakken
og lesa ei survey-boka. Og SSBs notat som ulike samplingsmåtar?

  
  Laging av eigne samanlikningfunksjonar (eiga avansert-kapittel).
  Og så må det stå om korleis standard samanlikningsfunksjon fungerer
  (spesielt om korleis handterer NA-verdiar).
  
Frå NORIC og AblaNor:
Me ønsker 
*-	at det skal vera mogleg å bestemma kva variabler som skal kontrollerast (til dømes dersom me veit at det er mykje feil i nokre felt vil me heller kontrollera dei felta enn tilfeldig utvalde variablar)
*-	å kunne avgrensa kor mange variabler som skal trekkjast ut + antal pasientar (Dersom prosjektet vert for stort er det vanskelig å finna ressursane til å gjennomføra det)
*-	at det er mogleg å avgrensa til utvalde sjukehus. (Til dømes dersom me veit at det er mykje feil i Stavanger kan me ha mål om å forbetra kvaliteten på innregistreringa der)
-	ein mal på korleis ein skal registrera samanlikningane ein gjer (Excel ark ein kan fylla inn i? Eller anna løysing? )
-	ein mal/døme på ferdig rapport. Til dømes flytskjema, oppteljingar per pasient/variabel med andel like/ulike registreringar, figurar 
-	gjerne ein halvautomatisert rapport. Me bruker rmd-format og tykkjer det fungerer fint. Kanskje ei rmd-fil me kan fylla parametre inn i kunne vore ein ide? Til dømes at me får første og siste registrering, dato for rapport, figurar, tabellar, overskrifter osv., så fyller me sjølve inn tekst og kompletterer ved behov. 

Sjå tekst og lenkjer på https://www.kvalitetsregistre.no/korrekthet
Verdt å merka seg:
*«For kontinuerlige variabler (eksempelvis høyde eller vekt) bør man også
analysere hvor stort avviket er fra den sanne verdien. En variabel hvor
avviket fra gullstandarden er stort er mer problematisk enn hvor
avviket er lite.»
Funksjon for å laga KI-variabel for kontinuerlege variablar?
Absoluttavvik (standard) eller avvik med forteikn?
  
-->
