---
title: "Ekstern validering"
author: "Per Erik Haugedal og Karl Ove Hufthammer"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
vignette: >
  %\VignetteIndexEntry{Ekstern validering}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r pakkelasting, include = FALSE}
suppressPackageStartupMessages({
  library(rapwhale)
  library(tidyverse)
  library(kableExtra)
})
```

```{r kable-format, include = FALSE}
lag_kable = function(d, full_width = FALSE, ...) {
  d %>%
    kbl() %>%
    kable_styling("hover", full_width = full_width, ...)
}
```

```{css, echo=FALSE}
/* Hack for å få tabellar til å flyt ut i margen om nødvendig
   (fixme: bør erstattast med eit felles, eksternt og
           gjennomtenkt stilsett for alle vignettane) */
table { float: left; }
p, h1, h2, h3, h4, h5, h6, div {
  clear: both;
}
```


## Innleiing

I `rapwhale` finst ein infrastruktur – eit sett R-funksjonar og tilhøyrande
metodikk – for *ekstern validering* av registerdata. Målet med denne
har vore å gjera det enklare, raskare og sikrare å gjennomføra ekstern
validering av høg kvalitet.

*Ekstern validering* går her ut på å finna ut om dataa i registeret er 
lik dataa i ein gitt gullstandard, typisk ein pasientjournal.
For meir informasjon, sjå
[SKDE sin artikkel om korrektheit](https://www.kvalitetsregistre.no/korrekthet).

Me har laga eit standardisert format for valideringsdata og
eit sett R-funksjonar for å analysera og laga datasett på dette formatet.
La oss først sjå nærare på formatet me har komme fram til.


## Format til valideringsdatasett

I eit valideringsdatsett må me for kvar måling
(for eksempel vekta eller høgda til ein person)
registrera verdien av målinga i registeret (*intern verdi*) og
tilhøyrande verdi i den eksterne kjelda (*ekstern verdi*), gullstandarden.
I tillegg treng me informasjon om kva pasient eller forløp
verdien gjeld samt kva for variabel det er snakk om.

### Første forsøk på eit format

I utgangspunktet verkar eit format som dette fornuftig:

```{r superenkelt eksempel, echo = FALSE}
d_banalt = tibble::tribble(
  ~pasid, ~varnamn, ~verdi_intern, ~verdi_ekstern,
  5, "vekt", 78, 78,
  7, "vekt", 53, 53,
  7, "hogd", 196, 186
)
lag_kable(d_banalt)
```

Her kan me registrera høgda og vekta til kvar pasient
(identifisert med pasient-ID, `pasid`),
både internt i registeret og i den eksterne kjelda.

Men for meir realistiske datasett støyter me fort på problem,
som me har løyst med eit utvida og endeleg format.


### Utvida og endeleg format

Det er tre potensielle problem –
at ein pasient kan ha *fleire målingar* av same variabel,
at me kan ha målingar av *ulike datatypar* (eksempelvis både tal og datoar)
og at indeksvariablar kan ha *same namn* som verdivariablane.

Ein pasient kan ha *fleire målingar* av same variabel
dersom han vore til fleire undersøkingar.
Det løyser me enkelt ved å tillata fleire *indeksvariablar*,
for eksempel både pasient-ID og undersøkingsdato.
Dette er variablar som saman med `vld_varnamn` unikt identifiserer kvar måling.
(Det svarar altså til *primærnøklar* i databasar.)

Eit register har vanlegvis målingar av *ulike datatypar*,
for eksempel både tal (som ovanfor) og datoar eller logiske variablar
(`TRUE`/`FALSE`).
Men i dei fleste datasystem kan ein kolonne berre innehalda data av éin type.
Dette løyser me ved å innføra fleire verdikolonnar,
éin for kvar datatype.
Me treng då òg ein kolonne (`vld_vartype`) som seier kva type variabel
som kvar verdi gjeld.

I sjeldne tilfelle har indeksvariablar *same namn* som verdivariablane.
Det prøver me å løysa ved at alle variablar utanom indeksvariablane
får prefikset *vld_* («validering»).
Dette vert då å rekna som eit reservert prefiks.

I det endelege formatet er det framleis slik at kvar rad
indentifiserer ei *måling* (med to verdiar, éin intern og éin ekstern):

```{r eksempel format, echo = FALSE}
d_vld = tibble::tribble(
  ~pasid, ~dato_inn, ~vld_varnamn, ~vld_vartype, ~vld_verdi_intern_dato, ~vld_verdi_ekstern_dato, ~vld_verdi_intern_tal, ~vld_verdi_ekstern_tal,
  5, as.Date("2020-06-07"), "vekt", "tal", NA, NA, 78, 78,
  5, as.Date("2020-06-07"), "dato_ut", "dato", as.Date("2020-06-15"), as.Date("2020-06-15"), NA, NA,
  5, as.Date("2020-12-13"), "vekt", "tal", NA, NA, NA, NA,
  5, as.Date("2020-12-13"), "dato_ut", "dato", as.Date("2020-12-13"), as.Date("2020-12-14"), NA, NA,
  7, as.Date("2020-08-07"), "vekt", "tal", NA, NA, 53, 53,
  7, as.Date("2020-08-09"), "hogd", "tal", NA, NA, 196, 194,
  7, as.Date("2020-08-09"), "dato_ut", "dato", as.Date("2020-08-13"), as.Date("2020-08-13"), NA, NA
)
lag_kable(d_vld)
```

Her utgjer `pasid` (pasient-ID) og `dato_inn` (innskrivingsdato)
indeksvariablane som *saman* unikt identifiserer ei måling (rad).
Pasient 5 har hatt to opphald og pasient 7 eitt.
(På det andre opphaldet til pasient 5 hadde ein gløymt å vega pasienten.)
Me vil samanlikna kva verdiar dei tre variablane
`vekt` (vekta til pasienten),
`hogd` (høgda til pasienten)
og `dato_ut` (utskrivingsdatoen for pasienten)
har i registeret med tilhøyrande verdiar i den eksterne kjelda.


## Bruk av valideringsdatasett

Når me har eit ferdig utfylt valideringsdatsett,
er det svært lett å samananlikna dei interne og eksterne verdiane.
Så kan me rekna ut statistikk som seier kor korrekte dataa er,
og til slutt kan me bruka statistikken i tabellar og
figurar i valideringsrapportar.

Valideringsdatasetta har me i R implementert som vanlege
datarammer/tibble-objekt:

```{r}
d_vld
```


### Samanlikning av interne og eksterne verdiar

Til å samanlikna verdiane brukar me `analyser_valideringsdatasett()`:

```{r samanlikning}
d_samanlikna = d_vld %>%
  analyser_valideringsdatasett()
```

```{r, echo = FALSE}
lag_kable(d_samanlikna)
```

Den nye kolonnen `ki_krit_teller` seier om dei interne og
dei eksterne verdiane er *like*.
Merk at to `NA`-verdiar som standard vert rekna som like
(noko som ikkje er vanleg i R).
Tanken bak dette er at om for eksempel `vekt` ikkje er registrert i registeret,
så *skal* heller ikkje vektinformasjon finnast i pasientjournalen,
og vice versa.

Men dersom gullstandarden og registeret ikkje har same *kjelde* til data,
for eksempel viss me samanliknar pasient- og legerapporterte data,
kan me ynskja eit visst slingringsmonn ved samanlikningane.
Me kan for eksempel ynskja at måling av vekt skal ha eit slingringsmonn
på 4 (kg), måling av høgd skal ha eit slingringsmonn på 2 (cm),
men operasjonsdatoen må vera heilt nøyaktig.
Dette kan ein få til ved å laga eigne *samanliknarfunksjonar*
(argumentet `samanliknar`).
Sjå meir om samanliknarfunksjonar i avsnitt **fixme**.



### Utrekning av korrektheitsstatistikk

Som vist ovanfor, legg `analyser_valideringsdatasett()` til *to* kolonnar,
`ki_krit_teller`, som me alt har sett på,
og `ki_krit_nevner`, som er `TRUE` for alle radene.
I praksis lagar me ein altså eit formelt kvalitetsindikator-datasett
(sjå **fixme: lenkje til vignett om kvalitetsindikatorar**),
noko som gjer at me kan bruka `aggreger_ki_prop()`
for å rekna ut korrektheitstatistikk,
både totalt og stratifisert på éin eller fleire variablar.


#### Total korrektheit

Total korrektheit reknar me ut direkte med `aggreger_ki_prop()`:

```{r aggregering total}
d_samanlikna %>%
  aggreger_ki_prop()
```

```{r, include=FALSE}
# Hack for å kunna ha tilgang til resultata i teksten
# utan å laga eksplisitt variabelnamn i eksempelet
d_agg_total = aggreger_ki_prop(d_samanlikna)
```

Her ser me at `r d_agg_total$ki_teller` av `r d_agg_total$ki_nevner`
(dvs. `r round(100*d_agg_total$est)` %)
av verdiane var like i registeret og gullstandarden.
Me får òg ut tilhøyrande 95 %-konfidensintervall.


#### Korrektheit per variabel

Nokre variablar er gjerne oftare korrekt registrerte enn andre.
Me kan lett få ut stratifisert statistikk ved å bruka `group_by()`:

```{r aggregering per-variabel}
d_samanlikna %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()
```

Tilsvarande kan me rekna ut korrektheit per sjukehus,
per variabel per sjukehus,
eller over tid (ved å ha år og månad som grupperingsvariablar).


#### Bruk av statistikken

Til slutt kan me visa statistikken i fine tabellar og figurar.
Her er eit komplett eksempel på bruk av eit valideringsdatasett,
med figur:

```{r, fig.width=5}
# Rekn ut korrektheit per variabel
d_korrektheit = d_vld %>%
  analyser_valideringsdatasett() %>%
  group_by(vld_varnamn) %>%
  aggreger_ki_prop()

# Eventuelt sorter for å få finare grafar og tabellar
d_korrektheit_sortert = d_korrektheit %>%
  arrange(est) %>%
  mutate(varnamn_sortert = forcats::fct_inorder(vld_varnamn))
# Brukte her arrange() for at resultatet lett skal kunna brukast
# i tabellar òg. Skal me berre laga grafar, kunne me heller bruka
# forcats::fct_reorder() direkte i mutate()-steget.
# I mutate()-steget kan me godt òg laga finare variabelnamn ...

# Enkel figur
library(ggplot2)
ggplot(
  d_korrektheit_sortert,
  aes(
    x = est, xmin = konfint_nedre, xmax = konfint_ovre,
    y = varnamn_sortert
  )
) +
  geom_pointrange() +
  scale_x_continuous(labels = scales::percent) +
  ggtitle("Korrektheit for utvalde variablar") +
  xlab("Korrekt") +
  ylab(NULL)
```

Her kan (og bør) me sjølvsagt finpussa figuren for å gjera
han meir brukarvennleg, men det er ikkje tema for denne vignetten.

Me tilrår elles òg *sterkt* å bruka SPC-metodikk,
*ikkje* konfidensintervall,
for samanlikning av korrektheit,
for eksempel mellom ulike sjukehus eller over tid,
men det er heller ikkje tema her.



## Generering av valideringsdatasett

Denne pakken har funksjonar for enkelt å laga klar valideringsdatasett.
Først treng me registerdata, lagra som eitt eller fleire datasett.
Så kan me bruka `lag_valideringsdatasett()` til å laga valideringsdatasett,
og til slutt kan me tilpassa dette datasettet slik at me
berre treng validera dei variablane og verdiane me er intersserte i.

### Eksempel på register

Me har eit enkelt register som registrerer vekt, høgd, om pasienten har opplevd
biverknadar, kva type biverknadar og om pasienten er gravid.
Nokre av variablane i registeret kan sjå slik ut:

```{r lageksempel, echo = FALSE}
d_reg_full = tibble::tribble(
  ~pasid, ~dato_inn, ~sjukehus, ~dato_ut, ~vekt, ~hogd, ~biverk, ~biverk_hovud, ~biverk_mage, ~biverk_fot, ~gravid,
  5, as.Date("2020-06-07"), "Bergen", as.Date("2020-06-15"), 78, 183, TRUE, FALSE, TRUE, TRUE, NA,
  5, as.Date("2020-12-13"), "Førde", as.Date("2020-12-13"), 50, 179, TRUE, FALSE, TRUE, TRUE, NA,
  7, as.Date("2020-08-09"), "Bergen", as.Date("2020-08-13"), 711, 196, TRUE, TRUE, TRUE, TRUE, TRUE,
  13, as.Date("2021-01-05"), "Førde", NA, NA, 163, FALSE, NA, NA, NA, NA,
  14, as.Date("2021-01-05"), "Førde", as.Date("2021-01-09"), 101, 182, TRUE, TRUE, FALSE, FALSE, NA
)
d_pas = tibble::tribble(
  ~pasid, ~kjonn,
  5, "mann",
  7, "kvinne",
  13, "mann",
  14, "mann"
)
lag_kable(d_reg_full)
```

I dette eksempelet er indeksvariablane `pasid` og `dato_inn`.
Sjukehus er alltid registrert rett,
så det er ein variabel me ikkje er interessert i å validera.
Me fjernar han derfor før me genererer valideringsdatasettet.

```{r fjern tilleggsvariablar}
d_reg = select(d_reg_full, -sjukehus)
```


### Komplett valideringsdatasett

Når me køyrer `lag_valideringsdatasett()`,
får me ut eit komplett valideringsdatasett,
der alle pasientar/forløp og alle datavariablar er med.
Talet på rader vert då lik talet på rader i det opphavlege datasettet 
gongar talet på datavariablar.
Her har me 5 pasientforløp og 8 *datavariablar*,
og me får såleis eit valideringsdatasett med 40 rader:

```{r lag eksempel valideringsdatasett}
d_vld = lag_valideringsdatasett(d_reg, indvars = c("pasid", "dato_inn"))
```

```{r eksempel valideringsdatasett, echo = FALSE}
d_vld %>%
  lag_kable()
```

For å ikkje få for breie tabellar
viser me berre nokre av kolonnane i dei vidare eksempla:

```{r}
d_vld_enkel = select(d_vld, pasid:vld_vartype)
```



### Tilfeldig rekkjefølgje og utval

Om me vil, kan me no validera *heile* datasettet
(ved å samanlikna det med gullstandraden).
Men i praksis vil me ta ein stikkprøve.

Kanskje har me berre tid til å validera ti målingar:

```{r}
set.seed(12345) # For reproduserbare «tilfeldige» trekkingar
slice_sample(d_vld_enkel, n = 10)
```

Eller ti prosent av datasettet:

```{r}
slice_sample(d_vld_enkel, prop = .1)
```

I nokre tilfelle kan me ikkje garantera tid til å
validera eit visst tal eller ein viss prosentdel av målingane.
Ei pragmatisk løysing er då gjera klar *heile* valideringsdatasettet,
men i tilfeldig rekkjefølgje.
Når me skal gjennomføra valideringa, startar me på toppen
og arbeider oss nedover.
Når me slepp opp for tid,
slettar me rett og slett dei resterande radene.
Me har likevel eit tilfeldig utval rader:

```{r}
slice_sample(d_vld_enkel, prop = 1)
```


### Valideringsdatasett med forløp i tilfeldig rekkjefølgje

Når me jamfører registerdata med for eksempel pasientjournalar,
er praktisk å sjå på alle datavariablane samla for kvar pasient,
slik at me ikkje heile tida må veksla mellom journalar.
Me har for eksempel fått denne stikkprøven med valideringsdata:

```{r}
d_vld_utval = d_vld_enkel[c(18, 32, 1, 40, 2, 17), ]
d_vld_utval
```

Her er ein enkel måte å samla dataa på,
men som samtidig sikrar
tilfeldig rekkjefølgje på pasientane (som er viktig for validiteten)

```{r}
set.seed(1) # For reproduserbare «tilfeldige» trekkingar
d_vld_utval_samla = d_vld_utval %>%
  group_by(pasid, dato_inn) %>% # Ev. bruk nest_by()
  nest() %>%
  ungroup() %>% # Nødvendig for slice_sample()
  slice_sample(prop = 1) %>%
  unnest(data)
d_vld_utval_samla
```

Viss me heller berre vil ha eit *utval* av forløpa,
endrar me berre `n`-verdien i `slice_sample()`.



### Variablar i fast rekkjefølgje

Det er gjerne praktisk at datavariablane kjem i same
rekkjefølgje for alle pasientane,
Det kan for eksempel vera rekkjefølgja opplysningane står
i i pasientjournalen.
Det ordnar me lett.

I dette eksempelet brukar me variabelrekkjefølgja
frå det opphavlege datasettet:

```{r}
var_rekkjefolgje = names(d_reg_full)
d_vld_utval %>%
  arrange(match(vld_varnamn, !!var_rekkjefolgje))
```

(Og så kan me bruka oppskrifta frå førre avsnitt for å få
dataa frå same pasient samla.)



### Tilfeldig utval av fast tal pasientar og variablar

Alt ovanfor kan sjølvsagt kombinerast.
Viss me vil trekkja 5 forløp og 2 variablar per forløp,
kan me gjera det slik:

```{r}
set.seed(1) # For reproduserbare «tilfeldige» trekkingar
n_forlop = 5 # Talet på forløp
n_var = 2 # Talet på variablar per forløp
d_vld_utval = d_vld_enkel %>%
  group_by(pasid, dato_inn) %>%
  slice_sample(n = n_var) %>%
  nest() %>%
  ungroup() %>% # Nødvendig for slice_sample()
  slice_sample(n = n_forlop) %>%
  unnest(data)
print(d_vld_utval, n = Inf) # 10 rader
```



### Utval av variablar i ferdige valideringsdatasett

Dersom ein berre skal sjå på eit utval av variablane,
kan me anten gjer dette *før* me lagar valideringsdatasettet
(slik me gjorde med `sjukehus`-variabelen)
eller ved filtrering etterpå.
Viss me for eksempel ikkje vil ha med biverknadsvariablane i
eit allereie laga valideringsdatasett,
kan me fjerna dei slik:

```{r fjern variabel}
d_vld %>%
  filter(!str_detect(vld_varnamn, "^biverk"))
```



#### Bruk av logikk til å fjerna unødvendige rader

Nokre variablar gjev berre meining å sjekka
dersom andre variablar har visse verdiar.
Variabelen `gravid` treng ein for eksempel berre sjekka
dersom pasienten er kvinne.

Merk at informasjon om kjønn ikkje finst i valideringsdatasettet,
så me hentar det frå eit anna datasett.
(Ein slik operasjon kan vera nyttig i mange samanhengar,
for eksempel for å hekta fødselsnummer på valideringsdatasett,
slik at det vert lettare å finna pasienten i pasientjournalen.)

```{r fjern rader med logikk}
# Koplar tabellen med kjønn på valideringsdatasettet
d_vld_med_kjonn = d_vld %>%
  left_join(d_pas, by = "pasid", relationship = "many-to-one")

# Filtrerer vekk rader som gjeld graviditet for «ikkje-kvinner» (inkl. NA-kjønn)
d_vld_med_kjonn %>%
  filter(!(vld_varnamn == "gravid" & kjonn != "kvinne"))
```

Logikken kan sjølvsagt skrivast på mange (ekvivalente) måtar, for eksempel:

```{r}
d_vld_med_kjonn %>%
  filter(vld_varnamn != "gravid" | kjonn == "kvinne")
```

Men ein kan lett gå seg bort i alle `!`-teikna og parentesane som trengst
for å uttrykka seg.
Me tilrår derfor å bruka `impl()`-funksjonen i `rapwhale`,
som er ein enkel måte å uttrykka sanningsverdiane i utsegn på forma
«A impliserer B» (altså «viss A, så B»).
I vårt eksempel er logikken «viss me ser på gravidvariabelen,
så må det vera for ei kvinne»:

```{r}
d_vld_med_kjonn %>%
  filter(impl(vld_varnamn == "gravid", kjonn == "kvinne"))
```



#### Logikk basert på fleire variablar

I nokre tilfelle kan samanhengen mellom variablane vera meir kompleks.
For eksempel fyller ein ut biverknads-«undervariablane»
`biverk_hovud`, `biverk_mage` og `biverk_fot`
viss og berre viss hovudvariabelen `biverk` er `TRUE`.
Det har ikkje noko for seg å sjekka
`biverk_hovud` viss `biverk` er `FALSE`
(gitt at innregistreringssystemet garanterer at ein
ikkje kan registrera inkonsistente verdiar,
og gitt at `biverk` alltid er til å stola på).

Her lagar me først eit uttrekk på vanleg vis,
og så fjernar me dei radene som ikkje skal vera med:

```{r}
# Først eit utkast til valideringsdatasett, to variablar per forløp
set.seed(1)
d_vld_utval_utkast = d_vld %>%
  group_by(pasid, dato_inn) %>%
  slice_sample(n = 2)

# Legg til info om hovud-biverknadsvariabel og filtrer på denne
d_reg_biverk = select(d_reg, pasid, dato_inn, biverk)
varnamn_undervar = c("biverk_hovud", "biverk_mage", "biverk_fot")
d_vld_utval_endeleg = d_vld_utval_utkast %>%
  left_join(d_reg_biverk,
    by = c("pasid", "dato_inn"),
    relationship = "many-to-one"
  ) %>%
  group_by(pasid, dato_inn) %>%
  filter(impl(vld_varnamn %in% !!varnamn_undervar, biverk))

# Talet på observasjonar i datasetta
nrow(d_vld_utval_utkast)
nrow(d_vld_utval_endeleg)
```


#### Logikk basert på faste variabelsett

Nokre gongar heng eit sett variablar så sterkt saman
at me vil sjå på / validera alle dersom me ser på minst éin av dei.
Viss me for eksempel for eit forløp skal validera variabelen for magebiverknadar,
vil me òg validera dei andre biverknadsvariablane, altså dei for
hovud- og fotbiverknadar samt den generelle biverknadsvariabelen.

Det er fleire måtar å få dette til på.
Her er eit eksempel der me,
i staden for å bruka `slice_sample()` til å filtrera vekk rader *direkte*,
først lagar ein «inklusjonsvariabel» som seier om den aktuelle rada
skal takast med (inkluderast) i valideringsdatasettet.
Dette mogleggjer meir avansert vidarebehandling,
der verdien til inklusjonsvariabelen kan avhenga av fleire rader:

```{r samanhengande variablar}
# Viss minst éin av desse variablane inngår i valideringsdatasettet
# for eit forløp, så skal alle gjera det
varnamn_biverk = c("biverk", "biverk_hovud", "biverk_mage", "biverk_fot")

# Skal bruka indeksvariablane fleire gongar, så lagrar dei
# for enkelheits skuld som ein eigen variabel
indeksvar = quos(pasid, dato_inn)

set.seed(57)
d_vld_utval_utkast = d_vld_enkel %>%
  group_by(!!!indeksvar) %>%
  mutate(inkluder = row_number() %in% sample(row_number(), 2)) # To verdiar per forløp
filter(d_vld_utval_utkast, inkluder)

# Generell hjelpefunksjon for å oppdatera inklusjonsstatus,
# der denne vert sett til TRUE for alle variablane med namn
# i «varnamn_gruppe» dersom minst éin av dei har
# inklusjonsstatus TRUE. Er meint å køyrast på grupperte datasett.
oppdater_inklusjonsstatus = function(inkluder, vld_varnamn, varnamn_gruppe) {
  er_variabel_i_gruppa = vld_varnamn %in% varnamn_gruppe
  if (any(inkluder[er_variabel_i_gruppa])) {
    inkluder[er_variabel_i_gruppa] = TRUE
  }
  inkluder
}

# Ta med alle biverknadsrader dersom minst éi er teken med (per forløp)
d_vld_utval_utkast = d_vld_utval_utkast %>%
  group_by(!!!indeksvar) %>%
  mutate(inkluder = oppdater_inklusjonsstatus(inkluder, vld_varnamn, !!varnamn_biverk))

# Fjern alle ikkje-inkluderte rader
d_vld_utval_endeleg = d_vld_utval_utkast %>%
  filter(inkluder) %>%
  select(-inkluder)
print(d_vld_utval_endeleg, n = Inf)
```




## Lagring og lesing av valideringsdatasett

### Eigna filformat og dataprogram for utfylling

Formatet på valideringsdatasetta er utforma slik
at datasetta lett kan brukast i ulike dataprogram/filformat.
Ein står fritt til sjølv å velja kva filformat ein vil bruka
når ein skal fylla ut valideringsdatasetta
med verdiane frå den eksterne kjelda.

Me tilrår likevel sterkt å bruka anten eit databaseverktøy
eller eit statistikkprogram *som sikrar dataintegriteten*.
Programmet bør sikra at ein for eksempel ikkje ved ein feil
skriv inn tekst eller tal i ein kolonne som berre tek datoar.

Både SPSS og Stata er statistikkprogram som er godt eigna.
Me **frårår på det sterkaste** å bruka Microsoft Excel.
Me viser her eit par eksempel på korleis ein kan lagra
valideringsdatasettet vårt til SPSS-format.


### Fullstendig valideringsdatasett til SPSS-format

For å lagra valideringsdatasettet som SPSS-format kan me bruka `write_sav()` 
frå `haven`-pakken:

```{r eval=FALSE}
# Definerer mappe og filnamn for lagring
mappe_vld = "h:\\valideringsdata\\"
filnamn = "valideringsdatasett.sav"
filadresse = paste0(mappe_vld, filnamn)

# Opprett mappa (om ho ikkje finst frå før)
dir.create(mappe_vld, showWarnings = FALSE, recursive = TRUE)

# Lagra valideringsdatasett på SPSS-format
haven::write_sav(d_vld, filadresse)
```

For lesing av ferdigredigerte valideringsfiler
brukar me tilsvarande `read_spss()`.


### Eitt valideringsdatasett per sjukehus til SPSS-format

Når me reiser rundt og validerer,
gjer me det jo for eitt og eitt sjukehus,
så ofte vil det vera føremålstenleg å ha éi fil per sjukehus.
Me har gjerne sjukehusinfo for kvart forløp lagra i eit separat datasett:

```{r, include=FALSE}
d_forlopsinfo = distinct(d_reg_full, pasid, dato_inn, sjukehus)
```

```{r}
d_forlopsinfo
```

Me må først kopla sjukehusnamna på valideringsdatasettet.
Me genererer så filnamn basert på desse namna.
For å få meir maskinvennlege filnamn brukar me i dette eksempelet
`to_any_case()`-funksjonen i `snakecase`-pakken.
(Slik me brukar han,
vil han for eksempel gjera om `"Helse Førde"` til `"helse_forde"`.)
Til slutt er det berre å dela opp valideringsdatasettet i eitt datasett
per sjukehus og lagra desse datasetta i separate filer:

```{r eval=FALSE}
# Hekt på sjukehusnamn
d_vld_med_sjukehus = d_vld %>%
  left_join(d_forlopsinfo,
    by = c("pasid", "dato_inn"),
    relationship = "many-to-one"
  )

# Generer maskinvennlege filadresser
library(snakecase)
d_vld_med_sjukehus = d_vld_med_sjukehus %>%
  mutate(
    filnamn = paste0(to_any_case(sjukehus, transliterations = "Latin-ASCII"), ".sav"),
    filadresse = paste0(mappe_vld, filnamn)
  )

# Del opp datasettet i eitt per sjukehus/filamn,
# og lagra dei som separate filer
d_vld_med_sjukehus %>%
  split(.$filadresse) %>%
  iwalk(write_sav)
```

Me kan bruka tilsvarande metodikk viss me vil ha éi fil
per årstal, per månad eller per sjukehus per månad.
Når me så har fylt ut valideringsdatasetta i SPSS,
kan me enkelt lasta dei alle inn *til eitt stort datasett* slik:

```{r eval = FALSE}
filadresser = list.files(mappe_vld, pattern = "\\.sav$", full.names = TRUE)
d_vld_utfylt = filadresser %>%
  map_dfr(read_sav)
```



## Statistiske avspekt ved bruk av valideringsdata

Korleis me vel ut tilfeldige målingar (*samplingsmetoden*),
påverkar *kva* storleikar me kan estimera og
*korleis* me kan estimera dei.

Me kan, som tidlegare vist, bruka enkelt tilfeldig utval og
ulike former stratifiserte utval.
Me skal no sjå nærare på dei statistiske eigenskapane
desse har, og til slutt skal me komma med nokre generelle
råd om samplings- og analysemetodar.


### Enkelt tilfeldig utval

La oss først tenkja oss at me plukkar ut *heilt tilfeldige* målingar
frå *heile* registeret (med `slice_sample()`,
anten eit visst tal målingar eller ein viss prosentdel).
Då kan me estimera blant anna desse storleikane direkte:

* Prosentdelen målingar som er rette i *heile registeret*
  (total korrektheit).
* Prosentdelen av éin type måling (eks. biverknadar) som er rett
  i heile registeret.
* Prosentdelen målingar som er rette *per sjukehus*.
* Prosentdelen av éin type måling som er rett per sjukehus.

Estimata (laga med `aggreger_ki_prop()`,
eventuelt med `group_by()` først)
vert forventingsrette og konfindensintervalla gyldige.

Denne samplingsmetoden er den enklaste og mest fleksible,
då han lett kan gje svar på *alle* moglege problemstillingar.
Men han har òg nokre ulemper.

La oss tenkja oss at me har eit register med tre sjukehus
av svært ulik storleik, og dermed ulikt pasienttal i registeret:

```{r, echo = FALSE}
d_sjukehus = tibble(
  Eining = paste0("Sjukehus ", LETTERS[1:3]),
  Pasientar = c(70, 400, 6700)
)
n_tot = sum(d_sjukehus$Pasientar)
n_plukk = 100
n_var = 10
lag_kable(d_sjukehus)
```

Kvar pasient er registrert med `r n_var` variablar.
Me plukkar `r n_plukk` tilfeldige målingar.
Då vert forventa tal på trekte målingar per sjukehus om lag:

```{r, echo = FALSE}
d_sjukehus2 = d_sjukehus %>%
  mutate(
    Målingar = Pasientar * n_var,
    Trekte = round(Målingar * n_plukk / sum(Målingar))
  )
lag_kable(d_sjukehus2)
```

Her kan me i *teorien* svara på alle spørsmåla ovanfor,
men det er klart at me likevel har *altfor få* målingar
frå sjukehus A til å seia noko om korrektheita
for dette sjukehuset.


### Stratifisert tilfeldig utval

Viss me er interesserte i tala *per sjukehus*,
kan me heller bruka ein samplingsmetode
der me plukkar ut like mange målingar per sjukehus:

```{r, echo = FALSE}
d_sjukehus3 = d_sjukehus2 %>%
  mutate(Trekte = 33)
lag_kable(d_sjukehus3)
```

Me kan så estimera kor stor del
av målingane som er korrekte per sjukehus,
og med om lag same presisjon for alle sjukehusa.
Estimata kan me bruka for å samanlikna sjukehusa
(gjerne med SPC-metodikk).
Då får me for eksempel:

```{r, echo = FALSE}
d_sjukehus4 = d_sjukehus3 %>%
  mutate(
    Trekte = 33,
    Korrekte = c(13, 25, 31),
    `Del korrekte` = round(Korrekte / Trekte, 2)
  )
n_korrekte = sum(d_sjukehus4$Korrekte)
n_trekte = sum(d_sjukehus4$Trekte)
lag_kable(d_sjukehus4)
```

Det ser ut til at det minste sjukehuset,
sjukehus A,
har lågast korrektheit.

Me kan òg bruka dei same dataa for direkte å svara
på korrektheit per variabel per sjukehus
(men bør sjølvsagt ha fleire trekte målingar
for å få presise estimat).

Men viss me vil ha svar på kor stor del av målingane
i *heile* registeret som er rette,
kan me ikkje lenger bruka `aggreger_ki_prop()` direkte.
Det vil gje både feil estimat og feil konfidensintervall.
Her vil det gje estimatat
(`r paste0(d_sjukehus4$Korrekte, collapse = " + ")`) / 
(`r paste0(d_sjukehus4$Trekte, collapse = " + ")`) = 
`r paste0(n_korrekte, " / ", n_trekte, " = ", format(round(n_korrekte/n_trekte, 2), nsmall=2))`.
Men dette svaret er openbert feil.
Dei dårlege resultata frå vesle sjukehus A har fått altfor stor vekt.

Metoden ovanfor vil nemleg berre vera gyldig dersom det ikkje finst
forskjellar i korrektheit mellom sjukehusa
eller dersom alle sjukehusa er like store
(har like mange målingar i registeret).

*Rett* analysemetode er å rekna ut eit *vekta* snitt av dei tre estimata,
vekta etter talet på *målingar* som er gjorde per sjukehus:

```{r, echo = FALSE}
d_sjukehus5 = d_sjukehus4 %>%
  select(-Pasientar) %>%
  mutate(`Del målingar` = Målingar / sum(Målingar))
n_bra_estimat = sum(d_sjukehus5$`Del korrekte` * d_sjukehus5$`Del målingar`)
d_sjukehus5$`Del målingar` = round(d_sjukehus5$`Del målingar`, 3)
lag_kable(d_sjukehus5)
```

Rett (og forventingsrett) estimat på kor stor del av
målingane i *heile registeret* som er korrekte,
vert då cirka `r round(n_bra_estimat, 2)`.
Dette estimatet er nært estimatetet til sjukehus C,
sidan dette sjukehuset har dei fleste pasientane/målingane i registeret.

Utrekning av tilhøyrande konfidensintervall vert meir komplisert.
Viss estimata ikkje er veldig små
og ikkje er baserte på veldig få observasjonar,
kan me rekna ut standardfeil for kvart av dei tre estimata,
rekna ut standardfeilen for ein vekta sum av uavhengige variablar,
og så bruka normaltilnærminga.
Men i praksis er det betre å bruka funksjonar i ein ferdig R-pakke,
for eksempel [`survey`-pakken](https://cran.r-project.org/package=survey).



### Råd ved komplisert sampling

Ved meir kompliserte samplingsmetodar må ein halda tunga
rett i munnen dersom ein vil rekna ut (forventings)rette estimat på
korrektheit – og tilhøyrande konfidensintervall.
Me tilrår å bruka `survey`-pakken og ta kontakt med ein statistikar.

Ein statistikar bør òg vera involvert når ein *vel* samplingsmetode i utgangspunktet,
for å sikra at ein seinare kan få (både rette og presise)
svar/estimat på dei spørsmåla ein ønskjer.

Viss det ikkje er veldig stor forskjell i storleiken på sjukehusa,
eller viss ein ikkje treng stratifiserte estimat,
tilrår me å bruka enkelt tilfeldig utval
(dvs. eit tilfeldig utval der alle relevante målingar i registeret
har likt sannsyn for å verta trekte).
Då gjer ein livet enklare for seg sjølv!

Til slutt har me nokre relevante litteraturkjelder
som de kan vurdera å lesa:

- [Complex Surveys: A Guide to Analysis Using R](http://r-survey.r-forge.r-project.org/svybook/)
  (bok om `survey`-pakken)
- [En praktisk innføring i utvalgsplanlegging](https://www.ssb.no/befolkning/artikler-og-publikasjoner/en-praktisk-innforing-i-utvalgsplanlegging) (notat frå SSB)

<!-- Behovskartlegging

  Laging av eigne samanlikningfunksjonar (eiga avansert-kapittel).
  Og så må det stå om korleis standard samanlikningsfunksjon fungerer
  (spesielt om korleis handterer NA-verdiar).
  
Sjå tekst og lenkjer på https://www.kvalitetsregistre.no/korrekthet
Verdt å merka seg:
*«For kontinuerlige variabler (eksempelvis høyde eller vekt) bør man også
analysere hvor stort avviket er fra den sanne verdien. En variabel hvor
avviket fra gullstandarden er stort er mer problematisk enn hvor
avviket er lite.»
Funksjon for å laga KI-variabel for kontinuerlege variablar?
Absoluttavvik (standard) eller avvik med forteikn?
  
-->
